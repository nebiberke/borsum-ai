{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10068647,"sourceType":"datasetVersion","datasetId":6205643}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pandas torch transformers datasets scikit-learn rouge-score bert-score sacrebleu","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-19T14:15:00.457387Z","iopub.execute_input":"2024-12-19T14:15:00.457812Z","iopub.status.idle":"2024-12-19T14:15:07.259806Z","shell.execute_reply.started":"2024-12-19T14:15:00.457766Z","shell.execute_reply":"2024-12-19T14:15:07.258742Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\nRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\nRequirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.2.0)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\nCollecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nCollecting bert-score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nCollecting sacrebleu\n  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (18.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge-score) (1.16.0)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score) (3.7.1)\nCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.4)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.3.0)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (4.53.1)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (1.4.7)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (10.4.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score) (3.1.4)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\nDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-3.0.0-py3-none-any.whl (19 kB)\nBuilding wheels for collected packages: rouge-score\n  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=b21f24dfba54e6e70f31a2c5a6c2ff58f0fa3ed76e9c8673f6aaa8af2a3e3644\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge-score\nInstalling collected packages: portalocker, sacrebleu, rouge-score, bert-score\nSuccessfully installed bert-score-0.3.13 portalocker-3.0.0 rouge-score-0.1.2 sacrebleu-2.4.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nfrom transformers import MT5Tokenizer, MT5ForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\nfrom datasets import Dataset, DatasetDict\nfrom sklearn.model_selection import train_test_split\nfrom rouge_score import rouge_scorer\nfrom bert_score import score as bert_score\nimport sacrebleu\nimport random","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T14:15:07.261191Z","iopub.execute_input":"2024-12-19T14:15:07.261517Z","iopub.status.idle":"2024-12-19T14:15:21.675799Z","shell.execute_reply.started":"2024-12-19T14:15:07.261489Z","shell.execute_reply":"2024-12-19T14:15:21.674919Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Load the dataset\ninput_path = '/kaggle/input/eco-news-me/haberler.csv'\nif not os.path.exists(input_path):\n    raise FileNotFoundError(f\"File not found: {input_path}\")\n\n# Read CSV file\ndf = pd.read_csv(input_path)\n\n# Drop rows with NaN values in 'icerik' or 'ozet' columns\ndf = df.dropna(subset=['icerik', 'ozet'])\n\n# Separate articles and summaries\narticles = df['icerik'].tolist()\nsummaries = df['ozet'].tolist()\n\n# Veriyi ilk olarak train ve test olarak ayırıyoruz\ntrain_articles, test_articles, train_summaries, test_summaries = train_test_split(\n    articles, summaries, test_size=0.2, random_state=42\n)\n\n# Train setini bir daha ayırarak train ve validation setlerini oluşturuyoruz\ntrain_articles, val_articles, train_summaries, val_summaries = train_test_split(\n    train_articles, train_summaries, test_size=0.1, random_state=42\n)\n\nprint(f\"Train set size: {len(train_articles)}\")\nprint(f\"Validation set size: {len(val_articles)}\")\nprint(f\"Test set size: {len(test_articles)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T14:15:21.677226Z","iopub.execute_input":"2024-12-19T14:15:21.677737Z","iopub.status.idle":"2024-12-19T14:15:21.725456Z","shell.execute_reply.started":"2024-12-19T14:15:21.677712Z","shell.execute_reply":"2024-12-19T14:15:21.724774Z"}},"outputs":[{"name":"stdout","text":"Train set size: 172\nValidation set size: 20\nTest set size: 48\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Her bir seti Hugging Face Dataset formatına dönüştürme\ntrain_data = {'article': train_articles, 'summary': train_summaries}\nval_data = {'article': val_articles, 'summary': val_summaries}\ntest_data = {'article': test_articles, 'summary': test_summaries}\n\ntrain_dataset = Dataset.from_dict(train_data)\nval_dataset = Dataset.from_dict(val_data)\ntest_dataset = Dataset.from_dict(test_data)\n\n# DatasetDict formatında birleştirme\ndataset = DatasetDict({\n    'train': train_dataset,\n    'validation': val_dataset,\n    'test': test_dataset\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T14:15:21.726584Z","iopub.execute_input":"2024-12-19T14:15:21.726821Z","iopub.status.idle":"2024-12-19T14:15:21.752832Z","shell.execute_reply.started":"2024-12-19T14:15:21.726799Z","shell.execute_reply":"2024-12-19T14:15:21.752010Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Load tokenizer and model\naccess_token = \"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\"\nmodel_name = 'nebiberke/haber-ozet-7000-mt5-base'\nmodel = MT5ForConditionalGeneration.from_pretrained(model_name, use_auth_token=access_token)\ntokenizer = MT5Tokenizer.from_pretrained(model_name, use_auth_token=access_token)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T14:15:21.753639Z","iopub.execute_input":"2024-12-19T14:15:21.753863Z","iopub.status.idle":"2024-12-19T14:16:31.100354Z","shell.execute_reply.started":"2024-12-19T14:15:21.753835Z","shell.execute_reply":"2024-12-19T14:16:31.099333Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:3220: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/827 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbe0daa713a94367a07594805a20d0c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92ac36ac04254d86ba3b7ddd3d95bdda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/142 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2f105a604f34b73bb342ed12bdc70c3"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2135: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/862 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f42c261d2134653906a7e38b036e986"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67d160064a10482cb2df8ca07eb1410f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/416 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0129657f9bfc4794a4f36dd42a2b569e"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T14:16:31.101344Z","iopub.execute_input":"2024-12-19T14:16:31.101609Z","iopub.status.idle":"2024-12-19T14:16:31.105575Z","shell.execute_reply.started":"2024-12-19T14:16:31.101587Z","shell.execute_reply":"2024-12-19T14:16:31.104753Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def preprocess_data(examples):\n    inputs = [f\"Özetle: {article}\" for article in examples[\"article\"]]\n    targets = examples['summary']\n    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n    labels = tokenizer(targets, max_length=150, truncation=True, padding=\"max_length\")\n    \n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n    \ntokenized_dataset = dataset.map(preprocess_data, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T14:16:31.106512Z","iopub.execute_input":"2024-12-19T14:16:31.106831Z","iopub.status.idle":"2024-12-19T14:16:32.839760Z","shell.execute_reply.started":"2024-12-19T14:16:31.106800Z","shell.execute_reply":"2024-12-19T14:16:32.838946Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/172 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad257cdde79a4aab86f905df45cac460"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/20 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"500f0b4db36444e6957851e0c2d71ba7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/48 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba763106720649978ee90721444a5b8d"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir='./results',\n    eval_strategy=\"epoch\",\n    save_strategy=\"no\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    num_train_epochs=100,\n    weight_decay=0.01,\n    predict_with_generate=True,\n    logging_dir='./logs',\n    report_to=\"none\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T14:16:32.841905Z","iopub.execute_input":"2024-12-19T14:16:32.842159Z","iopub.status.idle":"2024-12-19T14:16:32.945436Z","shell.execute_reply.started":"2024-12-19T14:16:32.842137Z","shell.execute_reply":"2024-12-19T14:16:32.944536Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Initialize Seq2SeqTrainer\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"validation\"],\n    data_collator=data_collator,\n)\n\n# Start training\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T14:16:32.946543Z","iopub.execute_input":"2024-12-19T14:16:32.946745Z","iopub.status.idle":"2024-12-19T15:00:17.709581Z","shell.execute_reply.started":"2024-12-19T14:16:32.946727Z","shell.execute_reply":"2024-12-19T15:00:17.708826Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='4300' max='4300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [4300/4300 43:41, Epoch 100/100]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.114089</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>1.065085</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>1.026795</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>No log</td>\n      <td>1.016514</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>No log</td>\n      <td>1.000731</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>No log</td>\n      <td>0.989660</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>No log</td>\n      <td>0.974735</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>No log</td>\n      <td>0.971039</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>No log</td>\n      <td>0.966871</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>No log</td>\n      <td>0.964467</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>No log</td>\n      <td>0.969879</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>1.087600</td>\n      <td>0.959923</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>1.087600</td>\n      <td>0.948339</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>1.087600</td>\n      <td>0.954119</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>1.087600</td>\n      <td>0.952665</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>1.087600</td>\n      <td>0.951862</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>1.087600</td>\n      <td>0.952425</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>1.087600</td>\n      <td>0.958798</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>1.087600</td>\n      <td>0.953505</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.087600</td>\n      <td>0.958578</td>\n    </tr>\n    <tr>\n      <td>21</td>\n      <td>1.087600</td>\n      <td>0.958951</td>\n    </tr>\n    <tr>\n      <td>22</td>\n      <td>1.087600</td>\n      <td>0.951605</td>\n    </tr>\n    <tr>\n      <td>23</td>\n      <td>1.087600</td>\n      <td>0.954681</td>\n    </tr>\n    <tr>\n      <td>24</td>\n      <td>0.819100</td>\n      <td>0.959504</td>\n    </tr>\n    <tr>\n      <td>25</td>\n      <td>0.819100</td>\n      <td>0.963331</td>\n    </tr>\n    <tr>\n      <td>26</td>\n      <td>0.819100</td>\n      <td>0.969891</td>\n    </tr>\n    <tr>\n      <td>27</td>\n      <td>0.819100</td>\n      <td>0.966075</td>\n    </tr>\n    <tr>\n      <td>28</td>\n      <td>0.819100</td>\n      <td>0.966309</td>\n    </tr>\n    <tr>\n      <td>29</td>\n      <td>0.819100</td>\n      <td>0.966541</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.819100</td>\n      <td>0.970260</td>\n    </tr>\n    <tr>\n      <td>31</td>\n      <td>0.819100</td>\n      <td>0.965699</td>\n    </tr>\n    <tr>\n      <td>32</td>\n      <td>0.819100</td>\n      <td>0.970597</td>\n    </tr>\n    <tr>\n      <td>33</td>\n      <td>0.819100</td>\n      <td>0.969847</td>\n    </tr>\n    <tr>\n      <td>34</td>\n      <td>0.819100</td>\n      <td>0.975797</td>\n    </tr>\n    <tr>\n      <td>35</td>\n      <td>0.676000</td>\n      <td>0.976384</td>\n    </tr>\n    <tr>\n      <td>36</td>\n      <td>0.676000</td>\n      <td>0.979972</td>\n    </tr>\n    <tr>\n      <td>37</td>\n      <td>0.676000</td>\n      <td>0.979449</td>\n    </tr>\n    <tr>\n      <td>38</td>\n      <td>0.676000</td>\n      <td>0.985779</td>\n    </tr>\n    <tr>\n      <td>39</td>\n      <td>0.676000</td>\n      <td>0.982095</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.676000</td>\n      <td>0.987690</td>\n    </tr>\n    <tr>\n      <td>41</td>\n      <td>0.676000</td>\n      <td>0.987821</td>\n    </tr>\n    <tr>\n      <td>42</td>\n      <td>0.676000</td>\n      <td>0.987206</td>\n    </tr>\n    <tr>\n      <td>43</td>\n      <td>0.676000</td>\n      <td>0.996076</td>\n    </tr>\n    <tr>\n      <td>44</td>\n      <td>0.676000</td>\n      <td>0.998344</td>\n    </tr>\n    <tr>\n      <td>45</td>\n      <td>0.676000</td>\n      <td>1.002530</td>\n    </tr>\n    <tr>\n      <td>46</td>\n      <td>0.676000</td>\n      <td>1.009753</td>\n    </tr>\n    <tr>\n      <td>47</td>\n      <td>0.581700</td>\n      <td>1.005169</td>\n    </tr>\n    <tr>\n      <td>48</td>\n      <td>0.581700</td>\n      <td>1.010297</td>\n    </tr>\n    <tr>\n      <td>49</td>\n      <td>0.581700</td>\n      <td>1.011551</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.581700</td>\n      <td>1.016425</td>\n    </tr>\n    <tr>\n      <td>51</td>\n      <td>0.581700</td>\n      <td>1.019412</td>\n    </tr>\n    <tr>\n      <td>52</td>\n      <td>0.581700</td>\n      <td>1.026560</td>\n    </tr>\n    <tr>\n      <td>53</td>\n      <td>0.581700</td>\n      <td>1.022066</td>\n    </tr>\n    <tr>\n      <td>54</td>\n      <td>0.581700</td>\n      <td>1.032640</td>\n    </tr>\n    <tr>\n      <td>55</td>\n      <td>0.581700</td>\n      <td>1.031072</td>\n    </tr>\n    <tr>\n      <td>56</td>\n      <td>0.581700</td>\n      <td>1.033820</td>\n    </tr>\n    <tr>\n      <td>57</td>\n      <td>0.581700</td>\n      <td>1.038022</td>\n    </tr>\n    <tr>\n      <td>58</td>\n      <td>0.581700</td>\n      <td>1.038493</td>\n    </tr>\n    <tr>\n      <td>59</td>\n      <td>0.513100</td>\n      <td>1.042424</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.513100</td>\n      <td>1.048685</td>\n    </tr>\n    <tr>\n      <td>61</td>\n      <td>0.513100</td>\n      <td>1.051735</td>\n    </tr>\n    <tr>\n      <td>62</td>\n      <td>0.513100</td>\n      <td>1.048356</td>\n    </tr>\n    <tr>\n      <td>63</td>\n      <td>0.513100</td>\n      <td>1.052234</td>\n    </tr>\n    <tr>\n      <td>64</td>\n      <td>0.513100</td>\n      <td>1.054898</td>\n    </tr>\n    <tr>\n      <td>65</td>\n      <td>0.513100</td>\n      <td>1.055546</td>\n    </tr>\n    <tr>\n      <td>66</td>\n      <td>0.513100</td>\n      <td>1.060221</td>\n    </tr>\n    <tr>\n      <td>67</td>\n      <td>0.513100</td>\n      <td>1.059526</td>\n    </tr>\n    <tr>\n      <td>68</td>\n      <td>0.513100</td>\n      <td>1.065579</td>\n    </tr>\n    <tr>\n      <td>69</td>\n      <td>0.513100</td>\n      <td>1.066960</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.463500</td>\n      <td>1.069375</td>\n    </tr>\n    <tr>\n      <td>71</td>\n      <td>0.463500</td>\n      <td>1.069653</td>\n    </tr>\n    <tr>\n      <td>72</td>\n      <td>0.463500</td>\n      <td>1.070118</td>\n    </tr>\n    <tr>\n      <td>73</td>\n      <td>0.463500</td>\n      <td>1.071823</td>\n    </tr>\n    <tr>\n      <td>74</td>\n      <td>0.463500</td>\n      <td>1.073351</td>\n    </tr>\n    <tr>\n      <td>75</td>\n      <td>0.463500</td>\n      <td>1.076638</td>\n    </tr>\n    <tr>\n      <td>76</td>\n      <td>0.463500</td>\n      <td>1.078865</td>\n    </tr>\n    <tr>\n      <td>77</td>\n      <td>0.463500</td>\n      <td>1.078938</td>\n    </tr>\n    <tr>\n      <td>78</td>\n      <td>0.463500</td>\n      <td>1.080135</td>\n    </tr>\n    <tr>\n      <td>79</td>\n      <td>0.463500</td>\n      <td>1.081083</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.463500</td>\n      <td>1.082910</td>\n    </tr>\n    <tr>\n      <td>81</td>\n      <td>0.463500</td>\n      <td>1.087869</td>\n    </tr>\n    <tr>\n      <td>82</td>\n      <td>0.430400</td>\n      <td>1.085973</td>\n    </tr>\n    <tr>\n      <td>83</td>\n      <td>0.430400</td>\n      <td>1.088081</td>\n    </tr>\n    <tr>\n      <td>84</td>\n      <td>0.430400</td>\n      <td>1.090808</td>\n    </tr>\n    <tr>\n      <td>85</td>\n      <td>0.430400</td>\n      <td>1.092126</td>\n    </tr>\n    <tr>\n      <td>86</td>\n      <td>0.430400</td>\n      <td>1.091494</td>\n    </tr>\n    <tr>\n      <td>87</td>\n      <td>0.430400</td>\n      <td>1.092145</td>\n    </tr>\n    <tr>\n      <td>88</td>\n      <td>0.430400</td>\n      <td>1.092519</td>\n    </tr>\n    <tr>\n      <td>89</td>\n      <td>0.430400</td>\n      <td>1.093779</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.430400</td>\n      <td>1.090471</td>\n    </tr>\n    <tr>\n      <td>91</td>\n      <td>0.430400</td>\n      <td>1.090159</td>\n    </tr>\n    <tr>\n      <td>92</td>\n      <td>0.430400</td>\n      <td>1.092369</td>\n    </tr>\n    <tr>\n      <td>93</td>\n      <td>0.430400</td>\n      <td>1.093031</td>\n    </tr>\n    <tr>\n      <td>94</td>\n      <td>0.413100</td>\n      <td>1.093576</td>\n    </tr>\n    <tr>\n      <td>95</td>\n      <td>0.413100</td>\n      <td>1.093996</td>\n    </tr>\n    <tr>\n      <td>96</td>\n      <td>0.413100</td>\n      <td>1.094720</td>\n    </tr>\n    <tr>\n      <td>97</td>\n      <td>0.413100</td>\n      <td>1.094767</td>\n    </tr>\n    <tr>\n      <td>98</td>\n      <td>0.413100</td>\n      <td>1.094752</td>\n    </tr>\n    <tr>\n      <td>99</td>\n      <td>0.413100</td>\n      <td>1.094732</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.413100</td>\n      <td>1.094709</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=4300, training_loss=0.6081750772165697, metrics={'train_runtime': 2622.6285, 'train_samples_per_second': 6.558, 'train_steps_per_second': 1.64, 'total_flos': 2.06235934654464e+16, 'train_loss': 0.6081750772165697, 'epoch': 100.0})"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# Save the fine-tuned model\nmodel.save_pretrained(\"fine_tuned_mt5-base_7000_ustune_200\")\ntokenizer.save_pretrained(\"fine_tuned_mt5-base_7000_ustune_200\")\n\nprint(\"Fine-tuning complete. Model and tokenizer saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T15:00:17.710582Z","iopub.execute_input":"2024-12-19T15:00:17.710922Z","iopub.status.idle":"2024-12-19T15:00:23.646083Z","shell.execute_reply.started":"2024-12-19T15:00:17.710888Z","shell.execute_reply":"2024-12-19T15:00:23.645287Z"}},"outputs":[{"name":"stdout","text":"Fine-tuning complete. Model and tokenizer saved.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"def generate_summary(model, tokenizer, text, max_length=150, min_length=30):\n    \"\"\"Haber metni için özet oluşturma.\"\"\"\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    text = f'Özetle {text}'\n    input_ids = tokenizer.encode(text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n    summary_ids = model.generate(input_ids, max_length=max_length, min_length=min_length, num_beams=4, early_stopping=True)\n    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T15:00:23.646903Z","iopub.execute_input":"2024-12-19T15:00:23.647205Z","iopub.status.idle":"2024-12-19T15:00:23.651975Z","shell.execute_reply.started":"2024-12-19T15:00:23.647171Z","shell.execute_reply":"2024-12-19T15:00:23.651131Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# ROUGE Hesaplama Fonksiyonu\ndef evaluate_rouge(model, tokenizer):\n    print(\"Calculating ROUGE scores...\")\n    rouge_results = []\n\n    for article, reference_summary in zip(test_articles, test_summaries):\n        predicted_summary = generate_summary(model, tokenizer, article)\n        rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n        scores = rouge.score(predicted_summary, reference_summary)\n        rouge_results.append({\n            \"rouge1_f1\": scores['rouge1'].fmeasure,\n            \"rouge2_f1\": scores['rouge2'].fmeasure,\n            \"rougeL_f1\": scores['rougeL'].fmeasure\n        })\n\n    avg_rouge = {\n        key: sum(d[key] for d in rouge_results) / len(rouge_results)\n        for key in rouge_results[0]\n    }\n    print(f\"Average ROUGE Scores: {avg_rouge}\")\n\n# BLEU Hesaplama Fonksiyonu\ndef evaluate_bleu(model, tokenizer):\n    print(\"Calculating BLEU scores...\")\n    bleu_results = []\n\n    for article, reference_summary in zip(test_articles, test_summaries):\n        predicted_summary = generate_summary(model, tokenizer, article)\n        bleu_score = sacrebleu.sentence_bleu(predicted_summary, [reference_summary]).score\n        bleu_results.append(bleu_score)\n\n    avg_bleu = sum(bleu_results) / len(bleu_results)\n    print(f\"Average BLEU Score: {avg_bleu:.4f}\")\n    # Corpus BLEU Hesaplama Fonksiyonu\n\ndef evaluate_corpus_bleu(model, tokenizer):\n    print(\"Calculating Corpus BLEU score...\")\n    predictions = []\n    references = []\n\n    for article, reference_summary in zip(test_articles, test_summaries):\n        predicted_summary = generate_summary(model, tokenizer, article)\n        predictions.append(predicted_summary)\n        references.append([reference_summary])  # SacreBLEU çoklu referansı destekler, bu yüzden liste içinde olmalı\n\n    bleu_score = sacrebleu.corpus_bleu(predictions, references).score\n    print(f\"Corpus BLEU Score: {bleu_score:.4f}\")\n\n# BERTScore Hesaplama Fonksiyonu\ndef evaluate_bertscore(model, tokenizer):\n    print(\"Calculating BERTScore...\")\n    bert_results = []\n\n    for article, reference_summary in zip(test_articles, test_summaries):\n        predicted_summary = generate_summary(model, tokenizer, article)\n        P, R, F1 = bert_score([predicted_summary], [reference_summary], lang=\"tr\")\n        bert_results.append(F1.mean().item())\n\n    avg_bert = sum(bert_results) / len(bert_results)\n    print(f\"Average BERTScore: {avg_bert:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T15:00:23.652859Z","iopub.execute_input":"2024-12-19T15:00:23.653140Z","iopub.status.idle":"2024-12-19T15:00:23.668937Z","shell.execute_reply.started":"2024-12-19T15:00:23.653103Z","shell.execute_reply":"2024-12-19T15:00:23.668097Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"evaluate_rouge(model, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T15:00:23.669782Z","iopub.execute_input":"2024-12-19T15:00:23.670180Z","iopub.status.idle":"2024-12-19T15:01:48.169303Z","shell.execute_reply.started":"2024-12-19T15:00:23.670146Z","shell.execute_reply":"2024-12-19T15:01:48.168203Z"}},"outputs":[{"name":"stdout","text":"Calculating ROUGE scores...\nAverage ROUGE Scores: {'rouge1_f1': 0.41339865700690015, 'rouge2_f1': 0.24803728008277817, 'rougeL_f1': 0.3252132393159644}\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"evaluate_bleu(model, tokenizer)\nevaluate_corpus_bleu(model, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T15:01:48.170099Z","iopub.execute_input":"2024-12-19T15:01:48.170362Z","iopub.status.idle":"2024-12-19T15:04:33.693385Z","shell.execute_reply.started":"2024-12-19T15:01:48.170339Z","shell.execute_reply":"2024-12-19T15:04:33.692599Z"}},"outputs":[{"name":"stdout","text":"Calculating BLEU scores...\nAverage BLEU Score: 12.8577\nCalculating Corpus BLEU score...\nCorpus BLEU Score: 27.3636\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"evaluate_bertscore(model, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T15:04:33.694118Z","iopub.execute_input":"2024-12-19T15:04:33.694337Z","iopub.status.idle":"2024-12-19T15:06:21.059257Z","shell.execute_reply.started":"2024-12-19T15:04:33.694318Z","shell.execute_reply":"2024-12-19T15:06:21.058450Z"}},"outputs":[{"name":"stdout","text":"Calculating BERTScore...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a82e46838784c7e9c5f9ad9b9f5f1ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a56dc551a984287a3367eda11ca0d88"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/251k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83735dc628dc4ce388ab60a871a53d49"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38327d6739fc49e1a0ecfb353cc22798"}},"metadata":{}},{"name":"stdout","text":"Average BERTScore: 0.6796\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import random\n# Rastgele bir örnek seçme\nrandom_index = random.randint(0, len(test_articles) - 1)\narticle = test_articles[random_index]\nreference_summary = test_summaries[random_index]\npredicted_summary = generate_summary(model, tokenizer, article)\n\n# Seçilen rastgele örneği yazdırma\nprint(f\"\\n------ Rastgele Seçilen Haber {random_index + 1} ------\")\nprint(f\"--- Orijinal Metin ---\\n{article}\")\nprint(f\"--- Modelin Oluşturduğu Özet ---\\n{predicted_summary}\")\nprint(f\"--- Gerçek Özet ---\\n{reference_summary}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-19T15:16:02.195197Z","iopub.execute_input":"2024-12-19T15:16:02.195573Z","iopub.status.idle":"2024-12-19T15:16:03.928243Z","shell.execute_reply.started":"2024-12-19T15:16:02.195549Z","shell.execute_reply":"2024-12-19T15:16:03.927388Z"}},"outputs":[{"name":"stdout","text":"\n------ Rastgele Seçilen Haber 8 ------\n--- Orijinal Metin ---\nOtokar Otomotiv ve Savunma Sanayi (OTKAR), bugün Kamuyu Aydınlatma Platformu’na gönderdiği açıklamada temettü kararı hakkında bilgi verdi. Açıklamada, şirketin 2023 yılında 1.9 milyar lira net dönem karı elde ettiği belirtilerek ortaklara ödenecek toplam kar payı tutarının 720 milyon lira olduğu kaydedildi. Otokar'ın hisse başına 5 lira 40 kuruş temettü ödemesinin kararlaştırıldığı ifade edildi. Temettünün dağıtılacağı tarih henüz açıklanmadı.\n--- Modelin Oluşturduğu Özet ---\nOtokar, hisse başına 5 lira 40 kuruş temettü ödemesi yapacak. Temettü ödemesi Kamuyu Aydınlatma Platformu'na (KAP) yapılan açıklamada, şirketin 2023 yılında 1.9 milyar TL net dönem karı elde edeceğini duyurdu. Temettü dağıtılacağı tarihte açıklanacak.\n--- Gerçek Özet ---\nOtokar, 2023 yılında elde ettiği 1,9 milyar TL net kar sonrası yatırımcılarına hisse başına 5,40 TL temettü ödeyeceğini duyurdu. Toplamda 720 milyon TL kar payı dağıtılacak, ancak dağıtım tarihi henüz açıklanmadı.\n\n","output_type":"stream"}],"execution_count":17}]}