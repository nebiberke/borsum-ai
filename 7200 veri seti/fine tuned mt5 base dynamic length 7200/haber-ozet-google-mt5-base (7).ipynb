{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9720602,"sourceType":"datasetVersion","datasetId":5947269},{"sourceId":9803653,"sourceType":"datasetVersion","datasetId":6008839}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pandas torch transformers datasets scikit-learn rouge-score bert-score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:16:53.692512Z","iopub.execute_input":"2024-11-23T09:16:53.693252Z","iopub.status.idle":"2024-11-23T09:17:05.477122Z","shell.execute_reply.started":"2024-11-23T09:16:53.693205Z","shell.execute_reply":"2024-11-23T09:17:05.476080Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nCollecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting bert-score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert-score) (3.7.5)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (10.3.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rouge-score\n  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=282027ef3f6c7bb2dd4a2dc01d75a7b0b3325b5dd9f373a17cba23b88580309a\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge-score\nInstalling collected packages: rouge-score, bert-score\nSuccessfully installed bert-score-0.3.13 rouge-score-0.1.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nfrom transformers import MT5Tokenizer, MT5ForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\nfrom datasets import Dataset, DatasetDict\nfrom sklearn.model_selection import train_test_split\nfrom rouge_score import rouge_scorer\nfrom bert_score import score as bert_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:17:13.254520Z","iopub.execute_input":"2024-11-23T09:17:13.255486Z","iopub.status.idle":"2024-11-23T09:17:31.751005Z","shell.execute_reply.started":"2024-11-23T09:17:13.255449Z","shell.execute_reply":"2024-11-23T09:17:31.750270Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Veri seti yolunun kontrolü\ninput_path = '/kaggle/input/eco-news-toplu/eco_news_cleaned3.csv'\nif not os.path.exists(input_path):\n    raise FileNotFoundError(f\"File not found: {input_path}\")\n\n# Veri setini okuma ve temizleme\ndf = pd.read_csv(input_path)\ndf = df.dropna(subset=['icerik', 'ozet'])  # 'icerik' ve 'ozet' sütunlarındaki NaN değerleri çıkar\n\n# Haberleri ve özetleri ayırma\narticles = df['icerik'].tolist()\nsummaries = df['ozet'].tolist()\n\n# Veriyi train-test olarak ayırma\ntrain_articles, test_articles, train_summaries, test_summaries = train_test_split(\n    articles, summaries, test_size=0.2, random_state=42\n)\n\n# Train-validation ayırma\ntrain_articles, val_articles, train_summaries, val_summaries = train_test_split(\n    train_articles, train_summaries, test_size=0.1, random_state=42\n)\n\nprint(f\"Train set size: {len(train_articles)}\")\nprint(f\"Validation set size: {len(val_articles)}\")\nprint(f\"Test set size: {len(test_articles)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:19:06.434981Z","iopub.execute_input":"2024-11-23T09:19:06.435996Z","iopub.status.idle":"2024-11-23T09:19:07.375987Z","shell.execute_reply.started":"2024-11-23T09:19:06.435947Z","shell.execute_reply":"2024-11-23T09:19:07.374931Z"}},"outputs":[{"name":"stdout","text":"Train set size: 5576\nValidation set size: 620\nTest set size: 1550\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Dataset formatına dönüştürme\ntrain_data = {'article': train_articles, 'summary': train_summaries}\nval_data = {'article': val_articles, 'summary': val_summaries}\ntest_data = {'article': test_articles, 'summary': test_summaries}\n\ntrain_dataset = Dataset.from_dict(train_data)\nval_dataset = Dataset.from_dict(val_data)\ntest_dataset = Dataset.from_dict(test_data)\n\ndataset = DatasetDict({\n    'train': train_dataset,\n    'validation': val_dataset,\n    'test': test_dataset\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:19:11.935076Z","iopub.execute_input":"2024-11-23T09:19:11.935931Z","iopub.status.idle":"2024-11-23T09:19:12.266764Z","shell.execute_reply.started":"2024-11-23T09:19:11.935896Z","shell.execute_reply":"2024-11-23T09:19:12.265902Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Model ve tokenizer yükleme\nmodel_name = 'google/mt5-base'\nmodel = MT5ForConditionalGeneration.from_pretrained(model_name)\ntokenizer = MT5Tokenizer.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:19:14.973639Z","iopub.execute_input":"2024-11-23T09:19:14.974001Z","iopub.status.idle":"2024-11-23T09:19:34.154767Z","shell.execute_reply.started":"2024-11-23T09:19:14.973970Z","shell.execute_reply":"2024-11-23T09:19:34.154001Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/702 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"554357d4f053493e8c4acb0709de144b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"493b5e2fa89a4c419c27d2dff1162da2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2162c29d55146489a6807e2838de456"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/376 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5e56f4939d894749be6b19f26148cf95"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a92bbc8abdd7481da72a9b91f7c12c47"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb8297020fb64ad8912afa593d21dbb7"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Dinamik `max_length` hesaplama fonksiyonu\ndef calculate_max_summary_length(article_length, min_length=50, max_length=150, ratio=0.2):\n    calculated_length = int(article_length * ratio)\n    return max(min_length, min(max_length, calculated_length))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:21:59.504195Z","iopub.execute_input":"2024-11-23T09:21:59.504562Z","iopub.status.idle":"2024-11-23T09:21:59.509163Z","shell.execute_reply.started":"2024-11-23T09:21:59.504535Z","shell.execute_reply":"2024-11-23T09:21:59.508218Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Dinamik `max_length` ve preprocessing fonksiyonu\ndef preprocess_data_with_dynamic_length(examples):\n    inputs = [f\"Özetle: {article}\" for article in examples[\"article\"]]\n    targets = examples[\"summary\"]\n\n    input_lengths = [len(tokenizer.tokenize(article)) for article in inputs]\n    max_summary_lengths = [calculate_max_summary_length(length) for length in input_lengths]\n\n    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n    \n    labels = []\n    for target, max_length in zip(targets, max_summary_lengths):\n        label = tokenizer(target, max_length=max_length, truncation=True, padding=\"max_length\")\n        labels.append(label[\"input_ids\"])\n    \n    model_inputs[\"labels\"] = labels\n    return model_inputs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:22:12.476352Z","iopub.execute_input":"2024-11-23T09:22:12.477045Z","iopub.status.idle":"2024-11-23T09:22:12.482902Z","shell.execute_reply.started":"2024-11-23T09:22:12.477008Z","shell.execute_reply":"2024-11-23T09:22:12.481803Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Preprocessing uygulama\ntokenized_dataset = dataset.map(preprocess_data_with_dynamic_length, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:22:16.598821Z","iopub.execute_input":"2024-11-23T09:22:16.599189Z","iopub.status.idle":"2024-11-23T09:22:55.053405Z","shell.execute_reply.started":"2024-11-23T09:22:16.599160Z","shell.execute_reply":"2024-11-23T09:22:55.052518Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5576 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d427cc9763146f5bd64408ca8ba0d80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/620 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1392f60d51f541fbba6e962b9824bdad"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1550 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6fb9e00233a74891b345ede3d230fb4d"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# Dinamik padding için data collator\ndata_collator = DataCollatorForSeq2Seq(\n    tokenizer=tokenizer, \n    model=model, \n    padding=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:23:16.387633Z","iopub.execute_input":"2024-11-23T09:23:16.388631Z","iopub.status.idle":"2024-11-23T09:23:16.393095Z","shell.execute_reply.started":"2024-11-23T09:23:16.388569Z","shell.execute_reply":"2024-11-23T09:23:16.392165Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir='./results',\n    eval_strategy=\"epoch\",\n    save_strategy=\"no\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    num_train_epochs=20,\n    weight_decay=0.01,\n    predict_with_generate=True,\n    logging_dir='./logs',\n    report_to=\"none\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:23:21.406964Z","iopub.execute_input":"2024-11-23T09:23:21.407613Z","iopub.status.idle":"2024-11-23T09:23:21.495818Z","shell.execute_reply.started":"2024-11-23T09:23:21.407573Z","shell.execute_reply":"2024-11-23T09:23:21.495116Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Seq2SeqTrainer ile model eğitimi\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"validation\"],\n    tokenizer=tokenizer,\n    data_collator=data_collator  # Dinamik padding burada aktif\n)\n\n# Start training\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T09:23:27.270723Z","iopub.execute_input":"2024-11-23T09:23:27.271114Z","iopub.status.idle":"2024-11-23T14:01:54.915138Z","shell.execute_reply.started":"2024-11-23T09:23:27.271080Z","shell.execute_reply":"2024-11-23T14:01:54.914356Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='27880' max='27880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [27880/27880 4:38:24, Epoch 20/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>3.205500</td>\n      <td>0.579072</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.654500</td>\n      <td>0.464366</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.558100</td>\n      <td>0.423599</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.503300</td>\n      <td>0.406274</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.476300</td>\n      <td>0.397948</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.460900</td>\n      <td>0.386195</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.433500</td>\n      <td>0.379903</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.410000</td>\n      <td>0.371167</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.400200</td>\n      <td>0.373508</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.380700</td>\n      <td>0.365852</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.387400</td>\n      <td>0.362824</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.374600</td>\n      <td>0.360559</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.374700</td>\n      <td>0.360462</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.355000</td>\n      <td>0.361781</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.357900</td>\n      <td>0.361310</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.342500</td>\n      <td>0.357623</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.337400</td>\n      <td>0.357964</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.339300</td>\n      <td>0.356582</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.333200</td>\n      <td>0.357513</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.349100</td>\n      <td>0.357567</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=27880, training_loss=0.8273323756892507, metrics={'train_runtime': 16705.4646, 'train_samples_per_second': 6.676, 'train_steps_per_second': 1.669, 'total_flos': 1.3371762460852224e+17, 'train_loss': 0.8273323756892507, 'epoch': 20.0})"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"!pip install sacrebleu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:04:44.000721Z","iopub.execute_input":"2024-11-23T14:04:44.001457Z","iopub.status.idle":"2024-11-23T14:04:52.361944Z","shell.execute_reply.started":"2024-11-23T14:04:44.001423Z","shell.execute_reply":"2024-11-23T14:04:52.361068Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Collecting sacrebleu\n  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2024.5.15)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (1.26.4)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.3.0)\nDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-3.0.0-py3-none-any.whl (19 kB)\nInstalling collected packages: portalocker, sacrebleu\nSuccessfully installed portalocker-3.0.0 sacrebleu-2.4.3\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import sacrebleu\n\n# Test veri kümesindeki orijinal metinler ve özetler\noriginal_texts = dataset['test']['article']\nreference_summaries = dataset['test']['summary']\n\n# Modelin tahmin ettiği özetler\ndef generate_summaries(model, tokenizer, texts, max_length=150, device='cuda'):\n    model.to(device)  # Modeli cihaza taşı\n    summaries = []\n    for text in texts:\n        # Girişleri cihaza taşı\n        inputs = tokenizer(f\"Özetle: {text}\", return_tensors=\"pt\", truncation=True, max_length=512).to(device)\n        \n        # Özet oluşturma\n        outputs = model.generate(\n            input_ids=inputs[\"input_ids\"], \n            attention_mask=inputs[\"attention_mask\"], \n            max_length=max_length, \n            num_beams=4, \n            early_stopping=True\n        )\n        \n        # Özetleri çöz ve listeye ekle\n        summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n        summaries.append(summary)\n    return summaries\n\n# Tahmin edilen özetler\npredicted_summaries = generate_summaries(model, tokenizer, original_texts)\n\n# ROUGE hesaplama\ndef calculate_rouge(reference_summaries, predicted_summaries):\n    scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n    rouge_scores = {'rouge1': [], 'rouge2': [], 'rougeL': []}\n    for ref, pred in zip(reference_summaries, predicted_summaries):\n        scores = scorer.score(ref, pred)\n        rouge_scores['rouge1'].append(scores['rouge1'].fmeasure)\n        rouge_scores['rouge2'].append(scores['rouge2'].fmeasure)\n        rouge_scores['rougeL'].append(scores['rougeL'].fmeasure)\n    # Ortalama ROUGE skorlarını döndür\n    return {key: sum(values)/len(values) for key, values in rouge_scores.items()}\n\n# BLEU hesaplama\ndef calculate_bleu(reference_summaries, predicted_summaries):\n    bleu = sacrebleu.corpus_bleu(predicted_summaries, [reference_summaries])\n    return bleu.score\n\n# BERTScore hesaplama\ndef calculate_bertscore(reference_summaries, predicted_summaries, lang='tr'):\n    P, R, F1 = bert_score(predicted_summaries, reference_summaries, lang=lang)\n    return {'Precision': P.mean().item(), 'Recall': R.mean().item(), 'F1': F1.mean().item()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:08:10.932767Z","iopub.execute_input":"2024-11-23T14:08:10.933183Z","iopub.status.idle":"2024-11-23T14:31:08.293888Z","shell.execute_reply.started":"2024-11-23T14:08:10.933153Z","shell.execute_reply":"2024-11-23T14:31:08.292809Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"rouge_results = calculate_rouge(reference_summaries, predicted_summaries)\nprint(\"ROUGE Scores:\", rouge_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:31:09.589536Z","iopub.execute_input":"2024-11-23T14:31:09.589770Z","iopub.status.idle":"2024-11-23T14:31:10.869049Z","shell.execute_reply.started":"2024-11-23T14:31:09.589746Z","shell.execute_reply":"2024-11-23T14:31:10.868172Z"}},"outputs":[{"name":"stdout","text":"ROUGE Scores: {'rouge1': 0.6444456485569592, 'rouge2': 0.5519392289045285, 'rougeL': 0.6200820095123559}\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"bleu_score = calculate_bleu(reference_summaries, predicted_summaries)\nprint(\"BLEU Score:\", bleu_score)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:33:42.989218Z","iopub.execute_input":"2024-11-23T14:33:42.989927Z","iopub.status.idle":"2024-11-23T14:33:43.339621Z","shell.execute_reply.started":"2024-11-23T14:33:42.989889Z","shell.execute_reply":"2024-11-23T14:33:43.338728Z"}},"outputs":[{"name":"stdout","text":"BLEU Score: 41.84931326448394\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"bertscore_results = calculate_bertscore(reference_summaries, predicted_summaries)\nprint(\"BERTScore:\", bertscore_results)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:33:46.039378Z","iopub.execute_input":"2024-11-23T14:33:46.040020Z","iopub.status.idle":"2024-11-23T14:33:57.581633Z","shell.execute_reply.started":"2024-11-23T14:33:46.039986Z","shell.execute_reply":"2024-11-23T14:33:57.580781Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3c1999bd4c3245adadf363856f2cf99a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43961150ca994bdf96da7f7164fd5698"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/251k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"980b59b399d14538b9bf54728d792592"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"effe0cae6bee4131bdb7c8e910f5047e"}},"metadata":{}},{"name":"stdout","text":"BERTScore: {'Precision': 0.8236191272735596, 'Recall': 0.8144460320472717, 'F1': 0.817284107208252}\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\n\n# Cihaz kontrolü (cuda varsa GPU'yu, yoksa CPU'yu seç)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Model ve tokenizer'ı cihaza taşı\nmodel.to(device)\n\n# Haber metninin uzunluğuna göre özet uzunluğunu hesaplayan fonksiyon\ndef calculate_summary_length(article_length, min_length=30, max_length=150, ratio=0.2):\n    dynamic_length = int(article_length * ratio)  # Haber uzunluğunun belirli bir oranı kadar özet oluştur\n    return max(min_length, min(max_length, dynamic_length))  # Sınırları kontrol et\n\n# Example data\nnews_text = \"\"\"Özetle: Türkiye Cumhuriyet Merkez Bankası (TCMB) bugün gerçekleştirilen Para Politikası Kurulu (PPK) toplantısında, politika faiz \noranını 200 baz puan artırarak yüzde 20 seviyesine yükseltti. Banka, bu kararı, enflasyonist baskılarla mücadele kapsamında aldığını belirtti. \nKararın ardından, döviz kurlarında ani yükselişler görülürken, borsa ise dalgalı bir seyir izledi. Ekonomistler, bu adımın enflasyonla mücadelede\nönemli bir sinyal olduğunu ve piyasaların orta vadede dengeye geleceğini öngörüyor. Öte yandan, iş dünyası temsilcileri ve yatırımcılar,\nfaiz artışının kredi maliyetlerini yükselteceğini ifade ederek kararı temkinli karşıladı. TCMB Başkanı, faiz artışlarının, enflasyonu dizginlemek\namacıyla kontrollü bir şekilde devam edebileceğini söyledi. Kararın etkisi önümüzdeki günlerde piyasalarda yakından izlenecek.\"\"\"\n\n# Haber metnini tokenizer ile işleyerek token haline getir (cihaza taşı)\ninput_ids = tokenizer.encode(\n    news_text, \n    return_tensors=\"pt\",  # Tensor formatında döndür\n    max_length=512,       # Maksimum uzunluk sınırı\n    truncation=True       # Uzun metinleri kes\n).to(device)\n\n# Haber metninin token uzunluğunu hesapla\narticle_length = input_ids.shape[1]  # Tensor'un ikinci boyutu (token sayısı)\n\n# Dinamik özet uzunluğunu hesapla\ndynamic_max_length = calculate_summary_length(article_length, ratio=0.25)\ndynamic_min_length = max(10, int(dynamic_max_length * 0.2))  # Minimum uzunluk, max_length'in %20'si kadar olsun\n\n# Özet oluşturma\nsummary_ids = model.generate(\n    input_ids, \n    max_length=dynamic_max_length,       # Dinamik maksimum uzunluk\n    min_length=dynamic_min_length,       # Dinamik minimum uzunluk\n    length_penalty=2.0,                  # Uzun özetleri tercih etmek için ceza oranı\n    num_beams=7,                         # Beam Search ile daha iyi özet oluşturma\n    early_stopping=True                  # İlk uygun özet bulunduğunda durdur\n)\n\n# Tokenize edilmiş özet metnini çözüp metin haline getir\nsummary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n\n# Özet çıktısını yazdır\nprint(\"Dynamic Max Length:\", dynamic_max_length)\nprint(\"Dynamic Min Length:\", dynamic_min_length)\nprint(\"Summary:\", summary)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:45:45.427874Z","iopub.execute_input":"2024-11-23T14:45:45.428539Z","iopub.status.idle":"2024-11-23T14:45:46.036689Z","shell.execute_reply.started":"2024-11-23T14:45:45.428504Z","shell.execute_reply":"2024-11-23T14:45:46.035886Z"}},"outputs":[{"name":"stdout","text":"Dynamic Max Length: 57\nDynamic Min Length: 11\nSummary: Türkiye Cumhuriyet Merkez Bankası, politika faiz oranını 200 baz puan artırarak yüzde 20 seviyesine yükseltti.\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"import random\nimport torch\n\n# Cihaz kontrolü\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Model ve tokenizer'ı cihaza taşı\nmodel.to(device)\n\n# Rastgele bir test örneği seçmek\ndef get_random_test_sample(dataset):\n    idx = random.randint(0, len(dataset['test']) - 1)  # Test setinden rastgele bir indeks seç\n    return dataset['test'][idx]\n\n# Modelin özet oluşturma fonksiyonu\ndef generate_summary_for_text(model, tokenizer, text, device, max_length=150, min_length=30):\n    # Haberi tokenize edip cihaza taşı\n    input_ids = tokenizer.encode(\n        f\"Özetle: {text}\",\n        return_tensors=\"pt\",\n        max_length=512,\n        truncation=True\n    ).to(device)\n\n    # Özet oluşturma\n    summary_ids = model.generate(\n        input_ids,\n        max_length=max_length,\n        min_length=min_length,\n        length_penalty=2.0,\n        num_beams=7,\n        early_stopping=True\n    )\n\n    # Özet metnini çöz\n    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n    return summary\n\n# Rastgele bir test haberi al\nsample = get_random_test_sample(dataset)\narticle = sample['article']\ntrue_summary = sample['summary']\n\n# Modelin ürettiği özeti oluştur\ngenerated_summary = generate_summary_for_text(model, tokenizer, article, device)\n\n# Karşılaştırmayı yazdırma\nprint(\"\\n=== Rastgele Bir Test Haberi ===\")\nprint(f\"Haber Metni:\\n{article}\")\nprint(\"\\n--- Gerçek Özet ---\")\nprint(f\"{true_summary}\")\nprint(\"\\n--- Modelin Ürettiği Özet ---\")\nprint(f\"{generated_summary}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:49:57.009685Z","iopub.execute_input":"2024-11-23T14:49:57.010064Z","iopub.status.idle":"2024-11-23T14:49:58.320481Z","shell.execute_reply.started":"2024-11-23T14:49:57.010032Z","shell.execute_reply":"2024-11-23T14:49:58.319589Z"}},"outputs":[{"name":"stdout","text":"\n=== Rastgele Bir Test Haberi ===\nHaber Metni:\n**Borsa İstanbul'da BIST 100 endeksi,** önceki kapanışa göre 16,92 puan azalırken, toplam işlem hacmi 32,1 milyar lira seviyesinde gerçekleşti.  Bankacılık endeksi yüzde 0,59 değer kaybederken, holding endeksi yüzde 0,58 değer kazandı. Sektör endeksleri arasında en fazla kazandıran yüzde 1,82 ile spor, en çok gerileyen ise yüzde 6,48 ile elektrik oldu.  Cumhurbaşkanı Recep Tayyip Erdoğan'ın \"müjde\" açıklamasıyla üç gündür dünya borsalarından pozitif ayrışan BIST 100 endeksi, bugün enerji hisselerinde yoğunlaşan alımlarla 1.141,32 puana kadar yükseldi. Kapanışa yakın kar satışları ile kazançlarını geri veren borsa günü yüzde 1,50 azalışla 1.109,88 puandan tamamladı.  Türkiye, tarihinin en büyük doğal gaz keşfini Karadeniz'de gerçekleştirirken, Erdoğan, \"Fatih Sondaj Gemimiz 20 Temmuz 2020'de başladığı Tuna 1 Kuyusu sondajında 320 milyar metroküp doğal gaz rezervi keşfetmiş durumda. Hedefimiz, 2023 yılında Karadeniz gazını milletimizin kullanımına sunmaktır.\" ifadelerini kullandı. Analistler, akşam saatlerinde yayımlanması beklenen uluslararası kredi derecelendirme kuruluşu Fitch Ratings'in Türkiye değerlendirmesinin izleneceğini belirterek, teknik açıdan BIST 100 endeksinde 1.120 ve 1.150 seviyelerinin direnç, 1.070 puanın destek konumunda olduğunu kaydetti.\n\n--- Gerçek Özet ---\nBorsa İstanbul'da BIST 100 endeksi, yüzde 1,50 değer kaybıyla günü 1.109,88 puandan tamamladı.\n\n--- Modelin Ürettiği Özet ---\nBorsa İstanbul'da BIST 100 endeksi, günü yüzde 1,50 azalışla 1.109,88 puandan tamamlayarak tüm zamanların en yüksek günlük kapanışını gerçekleştirirken, gördüğü en yüksek seviye rekorunu 1.109,88 puana taşıdı.\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import random\n\n# Validation veri setinin tamamında tahminler\npredictions = trainer.predict(tokenized_dataset[\"validation\"])\n\n# Tahmin edilen ve gerçek özetleri çözümleme\npredicted_summaries = [tokenizer.decode(ids, skip_special_tokens=True) for ids in predictions.predictions]\nreference_summaries = tokenized_dataset[\"validation\"][\"summary\"]\noriginal_articles = tokenized_dataset[\"validation\"][\"article\"]\n\n# ROUGE Skorlarını Hesaplama\nrouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\nrouge_scores = [rouge.score(pred, ref) for pred, ref in zip(predicted_summaries, reference_summaries)]\n\n# Ortalama ROUGE Skorlarını Hesaplama\nrouge1 = sum([score['rouge1'].fmeasure for score in rouge_scores]) / len(rouge_scores)\nrouge2 = sum([score['rouge2'].fmeasure for score in rouge_scores]) / len(rouge_scores)\nrougeL = sum([score['rougeL'].fmeasure for score in rouge_scores]) / len(rouge_scores)\n\nprint(f\"ROUGE-1 F1 Score: {rouge1:.4f}\")\nprint(f\"ROUGE-2 F1 Score: {rouge2:.4f}\")\nprint(f\"ROUGE-L F1 Score: {rougeL:.4f}\")\n\n# BERTScore Hesaplama (tüm doğrulama seti üzerinden)\nP, R, F1 = bert_score(predicted_summaries, reference_summaries, lang=\"tr\")  # 'tr' yerine uygun dili seçin\nbert_f1 = F1.mean().item()\n\nprint(\"-\"*50)\nprint(f\"BERTScore F1 Score: {bert_f1:.4f}\")\n\n# Rastgele bir örnek seçme\nrandom_index = random.randint(0, len(original_articles) - 1)\narticle = original_articles[random_index]\npredicted_summary = predicted_summaries[random_index]\nreference_summary = reference_summaries[random_index]\n\n# Seçilen rastgele örneği yazdırma\nprint(f\"\\n------ Rastgele Seçilen Haber {random_index + 1} ------\")\nprint(f\"--- Orijinal Metin ---\\n{article}\")\nprint(f\"--- Modelin Oluşturduğu Özet ---\\n{predicted_summary}\")\nprint(f\"--- Gerçek Özet ---\\n{reference_summary}\\n\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Load the fine-tuned model and tokenizer\nmodel_name = \"nebiberke/haber-ozet-mt5-base-ustune\"\nTOKEN = \"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\"\nmodel = MT5ForConditionalGeneration.from_pretrained(model_name, token=TOKEN)\ntokenizer = MT5Tokenizer.from_pretrained(model_name, token=TOKEN)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n\n# Sample news text to summarize\nnews_text = \"\"\"Yedi ülkede, 10 santral operasyonu ve dört farklı ülkede eş zamanlı devam eden yatırımlarıyla bugün itibarıyla toplam \n2,627 MW kurulu güce sahip olan Aksa Enerji, 2023 yılı konsolide finansal sonuçlarını açıkladı. Şirket, bir önceki yıla göre FAVÖK marjını \n7 puanlık artışla yüzde 22 seviyesine yükseltti, net kâr marjı ise 10 puan artışla yüzde 16’ya ulaştı. Aksa Enerji Yönetim Kurulu Başkanı ve \nCEO’su Cemil Kazancı, yıl sonu değerlendirmesinde, sürdürülebilir yüksek büyüme hedefi kapsamında devam eden yurt içi ve yurt dışı yatırımlara \nve etkin bilanço yönetimine dikkat çekti. Kazancı, “2023 yılında, coğrafi çeşitliliği artırmaya yönelik güçlü adımlar attık. Öte yandan hali \nhazırda faaliyet gösterdiğimiz ülkelerde sözleşmelerimizi yenileyerek kapasite artırımı gerçekleştirdik. Stratejik yatırımlarımızın kârlılığa \nolumlu etkisi ve etkin bilanço yönetimiyle birlikte yatırımlarımızın devam ettiği dönemde net finansal borcumuzun FAVÖK'e oranı 1,6 çarpan \nseviyesinde gerçekleşti. 2030 Stratejisi doğrultusunda, kurumsal dönüşüm hedeflerine paralel olarak fonksiyonel, mükemmeliyet merkezi yaklaşımına\nsahip, yalın, çevik ve güçlü bir organizasyon yapısı oluşturmak üzere çalışmalara devam edildiğini ileten Sn. Kazancı, üretim portföyünü yurt \niçinde de gerek kaynak gerekse coğrafi anlamda çeşitlendirmeye devam ettiklerini sözlerine ekledi. Sn. Kazancı, “Bu kapsamda 2023 yılı içerisinde \nİç Anadolu ve Ege Bölgeleri’nde, 8 şehirde toplam 831,41 MW kurulu güce sahip olacak RES ve GES depolamalı yenilenebilir enerji santrali ön \nlisansını almaya hak kazandık. Bu yatırımların önümüzdeki 5 yıllık süre zarfında faaliyete geçmesini planlıyoruz” dedi. Aksa Enerji’nin sağlam \n2023 yılı performansında karlılık odaklı portföy yönetimi etkili oldu. Şirket, 2023 yılı içerisinde Orta Asya ve Afrika gibi stratejik pazarlarda \nönemli yatırımlarda bulundu. Mart 2022’den beri 740MW’lık kurulu güç ile Özbekistan’da faaliyet gösteren Aksa Enerji, Kasım 2023 tarihinde \nTalimercan şehrinde 430 MW kurulu güçte bir doğal gaz kombine çevrim santrali kurulması ve işletilmesini içeren yeni bir anlaşma imzaladı. \nSantralin faaliyete geçmesiyle birlikte şirketin ülkedeki kurulu gücü 1,170 MW seviyesine çıkacak. Öte yandan Aksa Enerji, bu dönemde yeni bir \nanlaşma ile Orta Asya’daki yatırımlarına Kazakistan’ı da ekledi. Kazakistan’ın Kızılorda şehrindeki santral yatırımının hayata geçmesiyle birlikte \nAksa Enerji bölgeye ilk defa hem ısı hem de elektrik tedariği gerçekleştirecek. Kazakistan’daki büyüme hedefinin ilk ve önemli adımı olan \nbu santralin, 2025 yılında faaliyete geçmesi planlanıyor. Afrika kıtasında ise şirket, 2023 Nisan ayında Electricity Company of Ghana ile 350 MW \nkurulu gücünde Kumasi kombine çevrim doğal gaz santrali kurulumu, elektrik üretimi ve üretilen elektriğin garantili satışı konusunda anlaşma\nimzaladı. Anlaşmaya göre şirket, ABD doları bazlı 20 yıl süreli bir enerji satış anlaşması ile Gana’da doğal gaz dönüşümü ile sürdürülebilir\nenerjiye geçiş konusundaki adımlarını güçlendirdi. Bu yatırım atağı ile hedeflerinin Türkiye’nin küresel enerji piyasalarındaki konumunu \ngüçlendirirken aynı zamanda ülkelerin enerji arz güvenliğine hizmet etmek olduğunu belirten Sn. Cemil Kazancı, “Ülkemize duyduğumuz güven ve \nadanmışlıkla küresel piyasalardaki atılımlarımıza hız kattığımız bir dönemdeyiz. 2023 yılında gerçekleştirdiğimiz yeni anlaşmalarla Orta Asya’dan \nGüney Afrika’ya geniş bir coğrafyada enerji yatırımlarını hayata geçiriyoruz. Bu kapsamda Özbekistan Santrali Projesi’nin Aksa Enerji’nin varlık\nportföyündeki döviz bazlı gelirleri çeşitlendirerek ‘Sürdürülebilir Yüksek Büyüme’ stratejisini destekleyeceğine inanıyoruz. Talimercan ve \nKızılorda yatırımlarımız da yine bu stratejik yaklaşımın ürünleri. Önümüzdeki yıllarda faaliyete geçmesi planlanan Gana-Kumasi ve Senagal-St Louis \nsantral atılımımızla da ülkelerin enerji arz güvenliğine yatırım yapmaya devam ediyoruz. 2030 Stratejimizi kapsayan tüm bu çalışmalarımız, finansal\nbaşarımızı ve performansımızı güçlendirirken 5 kıtada faaliyet hedefimize de bizi adım adım yaklaştırıyor\"\"\"\n\n# Preprocess the text (tokenize and encode)\ninput_ids = tokenizer.encode(news_text, return_tensors=\"pt\", max_length=512, truncation=True).to('cuda')\n\n# Generate the summary\nsummary_ids = model.generate(input_ids, max_length=150, min_length=30, length_penalty=2.0, num_beams=7, early_stopping=True)\nsummary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n\n# Print the generated summary\nprint(\"Summary:\", summary)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Function to generate a summary\ndef generate_summary(text):\n    input_ids = tokenizer.encode(text, return_tensors=\"pt\", max_length=512, truncation=True)\n    summary_ids = model.generate(input_ids, max_length=150, min_length=30, length_penalty=2.0, num_beams=7, early_stopping=True)\n    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n\n# Example data\nnews_text = \"\"\"Özetle: Türkiye Cumhuriyet Merkez Bankası (TCMB) bugün gerçekleştirilen Para Politikası Kurulu (PPK) toplantısında, politika faiz \noranını 200 baz puan artırarak yüzde 20 seviyesine yükseltti. Banka, bu kararı, enflasyonist baskılarla mücadele kapsamında aldığını belirtti. \nKararın ardından, döviz kurlarında ani yükselişler görülürken, borsa ise dalgalı bir seyir izledi. Ekonomistler, bu adımın enflasyonla mücadelede\nönemli bir sinyal olduğunu ve piyasaların orta vadede dengeye geleceğini öngörüyor. Öte yandan, iş dünyası temsilcileri ve yatırımcılar,\nfaiz artışının kredi maliyetlerini yükselteceğini ifade ederek kararı temkinli karşıladı. TCMB Başkanı, faiz artışlarının, enflasyonu dizginlemek\namacıyla kontrollü bir şekilde devam edebileceğini söyledi. Kararın etkisi önümüzdeki günlerde piyasalarda yakından izlenecek.\"\"\"\nreference_summary = \"Merkez Bankası, enflasyonla mücadele için faiz oranını yüzde 20'ye yükseltti. Faiz artışı dövizde yükselişe, borsada dalgalanmaya yol açtı.\"\n\n# Generate a summary for the news text\ngenerated_summary = generate_summary(news_text)\nprint(\"Generated Summary:\", generated_summary)\n\n# Calculate ROUGE scores\nrouge_scorer_tool = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\nrouge_scores = rouge_scorer_tool.score(reference_summary, generated_summary)\n\n# Display ROUGE scores\nprint(\"ROUGE Scores:\")\nfor key, value in rouge_scores.items():\n    print(f\"{key}: Precision: {value.precision:.4f}, Recall: {value.recall:.4f}, F1-score: {value.fmeasure:.4f}\")\n\n# Calculate BERTScore\nP, R, F1 = bert_score([generated_summary], [reference_summary], lang=\"en\", verbose=True)\n\n# Display BERTScore\nprint(\"\\nBERTScore:\")\nprint(f\"Precision: {P.mean().item():.4f}, Recall: {R.mean().item():.4f}, F1-score: {F1.mean().item():.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Save the fine-tuned model\nmodel.save_pretrained(\"fine_tuned_mt5_base_dynamic_length\")\ntokenizer.save_pretrained(\"fine_tuned_mt5_base_dynamic_length\")\n\nprint(\"Fine-tuning complete. Model and tokenizer saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-23T14:50:50.910254Z","iopub.execute_input":"2024-11-23T14:50:50.910988Z","iopub.status.idle":"2024-11-23T14:50:56.261525Z","shell.execute_reply.started":"2024-11-23T14:50:50.910954Z","shell.execute_reply":"2024-11-23T14:50:56.260677Z"}},"outputs":[{"name":"stdout","text":"Fine-tuning complete. Model and tokenizer saved.\n","output_type":"stream"}],"execution_count":49}]}