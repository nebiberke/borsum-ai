{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9757576,"sourceType":"datasetVersion","datasetId":5974796},{"sourceId":9780208,"sourceType":"datasetVersion","datasetId":5991590}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pandas torch transformers datasets scikit-learn rouge-score bert-score sacrebleu","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-14T17:03:02.841657Z","iopub.execute_input":"2024-12-14T17:03:02.842095Z","iopub.status.idle":"2024-12-14T17:03:14.961567Z","shell.execute_reply.started":"2024-12-14T17:03:02.842062Z","shell.execute_reply":"2024-12-14T17:03:14.960512Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.3)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.1.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nCollecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting bert-score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nCollecting sacrebleu\n  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.26.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert-score) (3.7.5)\nCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.3.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (10.3.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-3.0.0-py3-none-any.whl (19 kB)\nBuilding wheels for collected packages: rouge-score\n  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=3496ccd6b31a53c73acb8dfe84b6c894dd4b2b1b6bab80a74f8fe8b599fc8625\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge-score\nInstalling collected packages: portalocker, sacrebleu, rouge-score, bert-score\nSuccessfully installed bert-score-0.3.13 portalocker-3.0.0 rouge-score-0.1.2 sacrebleu-2.4.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nfrom transformers import MT5Tokenizer, MT5ForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\nfrom datasets import Dataset, DatasetDict\nfrom sklearn.model_selection import train_test_split\nfrom rouge_score import rouge_scorer\nfrom bert_score import score as bert_score\nimport sacrebleu\nimport random","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T17:03:14.964070Z","iopub.execute_input":"2024-12-14T17:03:14.964448Z","iopub.status.idle":"2024-12-14T17:03:34.445009Z","shell.execute_reply.started":"2024-12-14T17:03:14.964407Z","shell.execute_reply":"2024-12-14T17:03:34.444312Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Load the dataset\ninput_path = '/kaggle/input/eco-news-toplu/eco_news_cleaned3.csv'\nif not os.path.exists(input_path):\n    raise FileNotFoundError(f\"File not found: {input_path}\")\n\n# Read CSV file\ndf = pd.read_csv(input_path)\n\n# Drop rows with NaN values in 'icerik' or 'ozet' columns\ndf = df.dropna(subset=['icerik', 'ozet'])\n\n# Separate articles and summaries\narticles = df['icerik'].tolist()\nsummaries = df['ozet'].tolist()\n\n# Veriyi ilk olarak train ve test olarak ayırıyoruz\ntrain_articles, test_articles, train_summaries, test_summaries = train_test_split(\n    articles, summaries, test_size=0.2, random_state=42\n)\n\n# Train setini bir daha ayırarak train ve validation setlerini oluşturuyoruz\ntrain_articles, val_articles, train_summaries, val_summaries = train_test_split(\n    train_articles, train_summaries, test_size=0.1, random_state=42\n)\n\nprint(f\"Train set size: {len(train_articles)}\")\nprint(f\"Validation set size: {len(val_articles)}\")\nprint(f\"Test set size: {len(test_articles)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T17:03:34.445999Z","iopub.execute_input":"2024-12-14T17:03:34.446500Z","iopub.status.idle":"2024-12-14T17:03:35.125175Z","shell.execute_reply.started":"2024-12-14T17:03:34.446471Z","shell.execute_reply":"2024-12-14T17:03:35.124305Z"}},"outputs":[{"name":"stdout","text":"Train set size: 5576\nValidation set size: 620\nTest set size: 1550\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Her bir seti Hugging Face Dataset formatına dönüştürme\ntrain_data = {'article': train_articles, 'summary': train_summaries}\nval_data = {'article': val_articles, 'summary': val_summaries}\ntest_data = {'article': test_articles, 'summary': test_summaries}\n\ntrain_dataset = Dataset.from_dict(train_data)\nval_dataset = Dataset.from_dict(val_data)\ntest_dataset = Dataset.from_dict(test_data)\n\n# DatasetDict formatında birleştirme\ndataset = DatasetDict({\n    'train': train_dataset,\n    'validation': val_dataset,\n    'test': test_dataset\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T17:03:35.126190Z","iopub.execute_input":"2024-12-14T17:03:35.126459Z","iopub.status.idle":"2024-12-14T17:03:35.450560Z","shell.execute_reply.started":"2024-12-14T17:03:35.126434Z","shell.execute_reply":"2024-12-14T17:03:35.449892Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Load tokenizer and model\nmodel_name = 'google/mt5-base'\nmodel = MT5ForConditionalGeneration.from_pretrained(model_name)\ntokenizer = MT5Tokenizer.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T17:03:35.453180Z","iopub.execute_input":"2024-12-14T17:03:35.453880Z","iopub.status.idle":"2024-12-14T17:03:50.770178Z","shell.execute_reply.started":"2024-12-14T17:03:35.453841Z","shell.execute_reply":"2024-12-14T17:03:50.769031Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/702 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bbe473eec27147dc9986385c29d63313"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13878ae375624fe2bc5872e2c3cad028"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"003d15c05ee549c88ce4b5320ed3b45c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/376 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"325bdbeeed134310916d30b37ad00db7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"12d8d261c4c34adb8237681b95f2885a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f4829560a04431da66bb23f6083458e"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/2.33G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74d46495ba0b46998c943af51cc7ad3e"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T17:03:50.771480Z","iopub.execute_input":"2024-12-14T17:03:50.771845Z","iopub.status.idle":"2024-12-14T17:03:50.776481Z","shell.execute_reply.started":"2024-12-14T17:03:50.771817Z","shell.execute_reply":"2024-12-14T17:03:50.775525Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def preprocess_data(examples):\n    inputs = [f\"Özetle: {article}\" for article in examples[\"article\"]]\n    targets = examples['summary']\n    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n    labels = tokenizer(targets, max_length=150, truncation=True, padding=\"max_length\")\n    \n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n    \ntokenized_dataset = dataset.map(preprocess_data, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T17:03:50.777836Z","iopub.execute_input":"2024-12-14T17:03:50.778086Z","iopub.status.idle":"2024-12-14T17:04:17.522446Z","shell.execute_reply.started":"2024-12-14T17:03:50.778062Z","shell.execute_reply":"2024-12-14T17:04:17.521428Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5576 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da914c8d8a984408ab7f33d822125e47"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/620 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9490c67665824d69a874f9602eb60312"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1550 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c54b4c6c1194b0286669e00ec521aa4"}},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir='./results',\n    eval_strategy=\"epoch\",\n    save_strategy=\"no\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    num_train_epochs=20,\n    weight_decay=0.01,\n    predict_with_generate=True,\n    logging_dir='./logs',\n    report_to=\"none\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T17:04:17.523864Z","iopub.execute_input":"2024-12-14T17:04:17.524134Z","iopub.status.idle":"2024-12-14T17:04:17.706746Z","shell.execute_reply.started":"2024-12-14T17:04:17.524108Z","shell.execute_reply":"2024-12-14T17:04:17.705636Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Initialize Seq2SeqTrainer\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"validation\"],\n    data_collator=data_collator,\n)\n\n# Start training\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T17:04:17.708341Z","iopub.execute_input":"2024-12-14T17:04:17.708942Z","iopub.status.idle":"2024-12-14T21:50:39.693817Z","shell.execute_reply.started":"2024-12-14T17:04:17.708902Z","shell.execute_reply":"2024-12-14T21:50:39.693018Z"}},"outputs":[{"name":"stderr","text":"Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='27880' max='27880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [27880/27880 4:46:18, Epoch 20/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>3.382600</td>\n      <td>0.536709</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.501800</td>\n      <td>0.325035</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.382500</td>\n      <td>0.280420</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.346400</td>\n      <td>0.273189</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.329700</td>\n      <td>0.263144</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.320500</td>\n      <td>0.254422</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.294400</td>\n      <td>0.249078</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.281400</td>\n      <td>0.243436</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.283900</td>\n      <td>0.244794</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.263700</td>\n      <td>0.241750</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.267600</td>\n      <td>0.236815</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.258500</td>\n      <td>0.236779</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.253200</td>\n      <td>0.239091</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.244300</td>\n      <td>0.236620</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.243500</td>\n      <td>0.236002</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.230200</td>\n      <td>0.234698</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.229200</td>\n      <td>0.234259</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.230000</td>\n      <td>0.234921</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.226900</td>\n      <td>0.234315</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.242700</td>\n      <td>0.234455</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=27880, training_loss=0.7404609048041586, metrics={'train_runtime': 17179.5512, 'train_samples_per_second': 6.491, 'train_steps_per_second': 1.623, 'total_flos': 1.3371762460852224e+17, 'train_loss': 0.7404609048041586, 'epoch': 20.0})"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# Save the fine-tuned model\nmodel.save_pretrained(\"fine_tuned_mt5-base_7200\")\ntokenizer.save_pretrained(\"fine_tuned_mt5-base_7200\")\n\nprint(\"Fine-tuning complete. Model and tokenizer saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T21:50:39.694951Z","iopub.execute_input":"2024-12-14T21:50:39.695310Z","iopub.status.idle":"2024-12-14T21:50:45.271722Z","shell.execute_reply.started":"2024-12-14T21:50:39.695271Z","shell.execute_reply":"2024-12-14T21:50:45.270859Z"}},"outputs":[{"name":"stdout","text":"Fine-tuning complete. Model and tokenizer saved.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"def generate_summary(model, tokenizer, text, max_length=150, min_length=30):\n    \"\"\"Haber metni için özet oluşturma.\"\"\"\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    text = f'Özetle {text}'\n    input_ids = tokenizer.encode(text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n    summary_ids = model.generate(input_ids, max_length=max_length, min_length=min_length, num_beams=4, early_stopping=True)\n    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T21:50:45.272948Z","iopub.execute_input":"2024-12-14T21:50:45.273593Z","iopub.status.idle":"2024-12-14T21:50:45.279034Z","shell.execute_reply.started":"2024-12-14T21:50:45.273553Z","shell.execute_reply":"2024-12-14T21:50:45.278138Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# ROUGE Hesaplama Fonksiyonu\ndef evaluate_rouge(model, tokenizer):\n    print(\"Calculating ROUGE scores...\")\n    rouge_results = []\n\n    for article, reference_summary in zip(test_articles, test_summaries):\n        predicted_summary = generate_summary(model, tokenizer, article)\n        rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n        scores = rouge.score(predicted_summary, reference_summary)\n        rouge_results.append({\n            \"rouge1_f1\": scores['rouge1'].fmeasure,\n            \"rouge2_f1\": scores['rouge2'].fmeasure,\n            \"rougeL_f1\": scores['rougeL'].fmeasure\n        })\n\n    avg_rouge = {\n        key: sum(d[key] for d in rouge_results) / len(rouge_results)\n        for key in rouge_results[0]\n    }\n    print(f\"Average ROUGE Scores: {avg_rouge}\")\n\n# BLEU Hesaplama Fonksiyonu\ndef evaluate_bleu(model, tokenizer):\n    print(\"Calculating BLEU scores...\")\n    bleu_results = []\n\n    for article, reference_summary in zip(test_articles, test_summaries):\n        predicted_summary = generate_summary(model, tokenizer, article)\n        bleu_score = sacrebleu.sentence_bleu(predicted_summary, [reference_summary]).score\n        bleu_results.append(bleu_score)\n\n    avg_bleu = sum(bleu_results) / len(bleu_results)\n    print(f\"Average BLEU Score: {avg_bleu:.4f}\")\n    # Corpus BLEU Hesaplama Fonksiyonu\n\ndef evaluate_corpus_bleu(model, tokenizer):\n    print(\"Calculating Corpus BLEU score...\")\n    predictions = []\n    references = []\n\n    for article, reference_summary in zip(test_articles, test_summaries):\n        predicted_summary = generate_summary(model, tokenizer, article)\n        predictions.append(predicted_summary)\n        references.append([reference_summary])  # SacreBLEU çoklu referansı destekler, bu yüzden liste içinde olmalı\n\n    bleu_score = sacrebleu.corpus_bleu(predictions, references).score\n    print(f\"Corpus BLEU Score: {bleu_score:.4f}\")\n\n# BERTScore Hesaplama Fonksiyonu\ndef evaluate_bertscore(model, tokenizer):\n    print(\"Calculating BERTScore...\")\n    bert_results = []\n\n    for article, reference_summary in zip(test_articles, test_summaries):\n        predicted_summary = generate_summary(model, tokenizer, article)\n        P, R, F1 = bert_score([predicted_summary], [reference_summary], lang=\"tr\")\n        bert_results.append(F1.mean().item())\n\n    avg_bert = sum(bert_results) / len(bert_results)\n    print(f\"Average BERTScore: {avg_bert:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T21:50:45.280353Z","iopub.execute_input":"2024-12-14T21:50:45.280863Z","iopub.status.idle":"2024-12-14T21:50:45.294752Z","shell.execute_reply.started":"2024-12-14T21:50:45.280824Z","shell.execute_reply":"2024-12-14T21:50:45.294040Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"evaluate_rouge(model, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T21:50:45.295795Z","iopub.execute_input":"2024-12-14T21:50:45.296116Z","iopub.status.idle":"2024-12-14T22:16:44.260997Z","shell.execute_reply.started":"2024-12-14T21:50:45.296080Z","shell.execute_reply":"2024-12-14T22:16:44.260075Z"}},"outputs":[{"name":"stdout","text":"Calculating ROUGE scores...\nAverage ROUGE Scores: {'rouge1_f1': 0.6002937514363476, 'rouge2_f1': 0.49924526596227137, 'rougeL_f1': 0.5724003102508476}\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"evaluate_bleu(model, tokenizer)\nevaluate_corpus_bleu(model, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T22:16:44.263217Z","iopub.execute_input":"2024-12-14T22:16:44.263470Z","iopub.status.idle":"2024-12-14T23:08:34.437462Z","shell.execute_reply.started":"2024-12-14T22:16:44.263446Z","shell.execute_reply":"2024-12-14T23:08:34.436561Z"}},"outputs":[{"name":"stdout","text":"Calculating BLEU scores...\nAverage BLEU Score: 39.2424\nCalculating Corpus BLEU score...\nCorpus BLEU Score: 59.1272\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"evaluate_bertscore(model, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T23:08:34.438871Z","iopub.execute_input":"2024-12-14T23:08:34.439137Z","iopub.status.idle":"2024-12-14T23:45:49.424157Z","shell.execute_reply.started":"2024-12-14T23:08:34.439111Z","shell.execute_reply":"2024-12-14T23:45:49.423220Z"}},"outputs":[{"name":"stdout","text":"Calculating BERTScore...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8be1d3a0545445abe5febb06c33988b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f659e12182a24b208b8422b9e864b1e4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/251k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f10b734bf6354231bf199c90654caec5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92da4fd951e44d0e9cd0994a092ed28f"}},"metadata":{}},{"name":"stdout","text":"Average BERTScore: 0.8014\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import random\n# Rastgele bir örnek seçme\nrandom_index = random.randint(0, len(test_articles) - 1)\narticle = test_articles[random_index]\nreference_summary = test_summaries[random_index]\npredicted_summary = generate_summary(model, tokenizer, article)\n\n# Seçilen rastgele örneği yazdırma\nprint(f\"\\n------ Rastgele Seçilen Haber {random_index + 1} ------\")\nprint(f\"--- Orijinal Metin ---\\n{article}\")\nprint(f\"--- Modelin Oluşturduğu Özet ---\\n{predicted_summary}\")\nprint(f\"--- Gerçek Özet ---\\n{reference_summary}\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-14T23:45:49.425437Z","iopub.execute_input":"2024-12-14T23:45:49.426153Z","iopub.status.idle":"2024-12-14T23:45:50.299900Z","shell.execute_reply.started":"2024-12-14T23:45:49.426112Z","shell.execute_reply":"2024-12-14T23:45:50.298998Z"}},"outputs":[{"name":"stdout","text":"\n------ Rastgele Seçilen Haber 1310 ------\n--- Orijinal Metin ---\n**Borsa İstanbul**'da **BIST 100 endeksi**, önceki **kapanış**a göre 0,61 puan azalırken, toplam işlem hacmi 19,7 milyar lira seviyesinde gerçekleşti.  Bankacılık endeksi yüzde 1,10 ve holding endeksi yüzde 0,37 değer kazandı. Sektör endeksleri arasında en fazla kazandıran yüzde 1,28 ile metal eşya makine, en çok gerileyen ise yüzde 9,93 ile spor oldu.  Güne yükselişle başlayan ve bankacılık hisselerinde yoğunlaşan alımların etkisiyle 1.105,98 puanı gören BIST 100 endeksi, kapanışa yakın kazançlarını geri vererek günü yüzde 0,06 düşüşle 1.099,06 puandan tamamladı.  Analistler, yarın yurt içinde temmuz ayı ödemeler dengesi istatistikleri, yurt dışında ise İngiltere'de sanayi üretimi, Avro Bölgesi, Almanya ve ABD'de Tüketici Fiyat Endeksi verilerinin takip edileceğini bildirdi.  Yeni tip koronavirüs tedavisine ilişkin haber akışı ve Doğu Akdeniz başta olmak üzere jeopolitik gelişmelerin gündemin odağındaki yerini koruduğunu belirten analistler, ABD'de teknoloji hisselerindeki aşırı oynaklık nedeniyle bu hisselerdeki hareketliliğin küresel ölçekte risk algısı üzerinde belirleyici olacağını söyledi.  Analistler, teknik açıdan BIST 100 endeksinde 1.120 puanın direnç olarak öne çıktığını, 1.090 ve 1.070 seviyelerinin destek konumunda olduğunu kaydetti. AA Finans Ödemeler Dengesi Beklenti Anketi'ne katılan ekonomistler, cari işlemler hesabının temmuzda 1,9 milyar dolar açık vermesini bekliyor. Ekonomistlerin söz konusu dönem için cari işlemler açığı beklentisi, 800 milyon dolar ila 2,8 milyar dolar arasında yer aldı. Cari işlemler dengesi, haziranda 2 milyar 934 milyon dolar açık verirken, 12 aylık cari açık 11 milyar 94 milyon dolar olmuştu.\n--- Modelin Oluşturduğu Özet ---\nBorsa İstanbul'da BIST 100 endeksi, günü yüzde 0,06 düşüşle 1.099,06 puandan tamamladı.\n--- Gerçek Özet ---\nBorsa İstanbul'da BIST 100 endeksi, yüzde 0,06 değer kaybıyla günü 1.099,06 puandan tamamladı.\n\n","output_type":"stream"}],"execution_count":16}]}