{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9803653,"sourceType":"datasetVersion","datasetId":6008839}],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pandas torch transformers datasets scikit-learn rouge-score bert-score peft sacrebleu","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-11T23:41:38.861610Z","iopub.execute_input":"2024-12-11T23:41:38.862486Z","iopub.status.idle":"2024-12-11T23:41:51.502532Z","shell.execute_reply.started":"2024-12-11T23:41:38.862448Z","shell.execute_reply":"2024-12-11T23:41:51.501489Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.3)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.1.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nCollecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting bert-score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nCollecting peft\n  Downloading peft-0.14.0-py3-none-any.whl.metadata (13 kB)\nCollecting sacrebleu\n  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.26.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert-score) (3.7.5)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft) (1.1.1)\nCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.3.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (10.3.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading peft-0.14.0-py3-none-any.whl (374 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.8/374.8 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-3.0.0-py3-none-any.whl (19 kB)\nBuilding wheels for collected packages: rouge-score\n  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=e6f3f051d260a0774916ba10dd44caf3ad951851b53c390e075dc0ccb3cd049f\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge-score\nInstalling collected packages: portalocker, sacrebleu, rouge-score, peft, bert-score\nSuccessfully installed bert-score-0.3.13 peft-0.14.0 portalocker-3.0.0 rouge-score-0.1.2 sacrebleu-2.4.3\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nimport random\nfrom transformers import MBartForConditionalGeneration, MBart50TokenizerFast, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\nfrom datasets import Dataset, DatasetDict\nfrom sklearn.model_selection import train_test_split\nfrom rouge_score import rouge_scorer\nfrom bert_score import score as bert_score\nfrom peft import LoraConfig, get_peft_model, TaskType","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T23:42:29.131534Z","iopub.execute_input":"2024-12-11T23:42:29.132256Z","iopub.status.idle":"2024-12-11T23:42:29.137567Z","shell.execute_reply.started":"2024-12-11T23:42:29.132222Z","shell.execute_reply":"2024-12-11T23:42:29.136422Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Load the dataset\ninput_path = '/kaggle/input/eco-news-toplu/eco_news_cleaned3.csv'\nif not os.path.exists(input_path):\n    raise FileNotFoundError(f\"File not found: {input_path}\")\n\n# Read CSV file\ndf = pd.read_csv(input_path)\n\n# Drop rows with NaN values in 'icerik' or 'ozet' columns\ndf = df.dropna(subset=['icerik', 'ozet'])\n\n# Separate articles and summaries\narticles = df['icerik'].tolist()\nsummaries = df['ozet'].tolist()\n\n# Veriyi ilk olarak train ve test olarak ayırıyoruz\ntrain_articles, test_articles, train_summaries, test_summaries = train_test_split(\n    articles, summaries, test_size=0.2, random_state=42\n)\n\n# Train setini bir daha ayırarak train ve validation setlerini oluşturuyoruz\ntrain_articles, val_articles, train_summaries, val_summaries = train_test_split(\n    train_articles, train_summaries, test_size=0.1, random_state=42\n)\n\nprint(f\"Train set size: {len(train_articles)}\")\nprint(f\"Validation set size: {len(val_articles)}\")\nprint(f\"Test set size: {len(test_articles)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T23:42:31.247855Z","iopub.execute_input":"2024-12-11T23:42:31.248265Z","iopub.status.idle":"2024-12-11T23:42:32.093448Z","shell.execute_reply.started":"2024-12-11T23:42:31.248229Z","shell.execute_reply":"2024-12-11T23:42:32.092461Z"}},"outputs":[{"name":"stdout","text":"Train set size: 5576\nValidation set size: 620\nTest set size: 1550\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Her bir seti Hugging Face Dataset formatına dönüştürme\ntrain_data = {'article': train_articles, 'summary': train_summaries}\nval_data = {'article': val_articles, 'summary': val_summaries}\ntest_data = {'article': test_articles, 'summary': test_summaries}\n\ntrain_dataset = Dataset.from_dict(train_data)\nval_dataset = Dataset.from_dict(val_data)\ntest_dataset = Dataset.from_dict(test_data)\n\n# DatasetDict formatında birleştirme\ndataset = DatasetDict({\n    'train': train_dataset,\n    'validation': val_dataset,\n    'test': test_dataset\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T23:42:34.725427Z","iopub.execute_input":"2024-12-11T23:42:34.725792Z","iopub.status.idle":"2024-12-11T23:42:35.059941Z","shell.execute_reply.started":"2024-12-11T23:42:34.725762Z","shell.execute_reply":"2024-12-11T23:42:35.059263Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Load tokenizer and model\nmodel_name = 'facebook/mbart-large-50'\nmodel = MBartForConditionalGeneration.from_pretrained(model_name)\ntokenizer = MBart50TokenizerFast.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T23:42:37.606946Z","iopub.execute_input":"2024-12-11T23:42:37.607782Z","iopub.status.idle":"2024-12-11T23:42:53.819967Z","shell.execute_reply.started":"2024-12-11T23:42:37.607746Z","shell.execute_reply":"2024-12-11T23:42:53.818455Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"344a7162ff294004a29adde67698d1ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.44G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6a53123a5cf4309b19c74ede9b0bff0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/261 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c73d0ba0cd784551a4a3e1a139c57501"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/531 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55f66b2db9184ab596bb019002e1a9d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b17db828e1e64ae88a11adeb09bb9452"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/649 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0c2dcae2c84494daa3bb36a950f158e"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T23:43:04.662701Z","iopub.execute_input":"2024-12-11T23:43:04.663070Z","iopub.status.idle":"2024-12-11T23:43:04.667002Z","shell.execute_reply.started":"2024-12-11T23:43:04.663024Z","shell.execute_reply":"2024-12-11T23:43:04.666209Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def preprocess_data(examples):\n    inputs = [f\"Özetle: {article}\" for article in examples[\"article\"]]\n    targets = examples['summary']\n    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n    labels = tokenizer(targets, max_length=150, truncation=True, padding=\"max_length\")\n    \n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\ntokenized_dataset = dataset.map(preprocess_data, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T23:43:07.768519Z","iopub.execute_input":"2024-12-11T23:43:07.768891Z","iopub.status.idle":"2024-12-11T23:43:17.699224Z","shell.execute_reply.started":"2024-12-11T23:43:07.768861Z","shell.execute_reply":"2024-12-11T23:43:17.698266Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5576 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"324c5d20aedc45f8b04378c346f2d725"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/620 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b468cd63de744303aa9fc24ecc3dfd0a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1550 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e97d7f4115b34234b6b669f4e886cab5"}},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# Eğitim ve doğrulama setini küçültme\n#tokenized_dataset[\"train\"] = tokenized_dataset[\"train\"].filter(lambda example, index: index % 100 == 0, with_indices=True)\n#tokenized_dataset[\"validation\"] = tokenized_dataset[\"validation\"].filter(lambda example, index: index % 100 == 0, with_indices=True)\n#tokenized_dataset[\"test\"] = tokenized_dataset[\"test\"].filter(lambda example, index: index % 100 == 0, with_indices=True)\n\n\n# Veri seti uzunluğunu yazdırma\n#print(f\"Filtered train set size: {len(tokenized_dataset['train'])}\")\n#print(f\"Filtered validation set size: {len(tokenized_dataset['validation'])}\")\n#print(f\"Filtered test set size: {len(tokenized_dataset['test'])}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for name, module in model.named_modules():\n    print(name)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=32,\n    lora_alpha=64,\n    lora_dropout=0.1,\n    bias='none',\n    task_type=TaskType.SEQ_2_SEQ_LM,\n    target_modules=[\"q_proj\", \"v_proj\"],\n)\n\nmodel = get_peft_model(model, lora_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T23:47:33.721711Z","iopub.execute_input":"2024-12-11T23:47:33.722126Z","iopub.status.idle":"2024-12-11T23:47:33.854310Z","shell.execute_reply.started":"2024-12-11T23:47:33.722092Z","shell.execute_reply":"2024-12-11T23:47:33.853550Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir='./results',\n    eval_strategy=\"epoch\",\n    save_strategy=\"no\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    num_train_epochs=20,\n    weight_decay=0.01,\n    predict_with_generate=True,\n    logging_dir='./logs',\n    report_to=\"none\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T23:48:29.523157Z","iopub.execute_input":"2024-12-11T23:48:29.523901Z","iopub.status.idle":"2024-12-11T23:48:29.636861Z","shell.execute_reply.started":"2024-12-11T23:48:29.523868Z","shell.execute_reply":"2024-12-11T23:48:29.636087Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Initialize Seq2SeqTrainer\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"validation\"],\n    data_collator=data_collator,\n)\n\n# Start training\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-11T23:48:33.075841Z","iopub.execute_input":"2024-12-11T23:48:33.076625Z","iopub.status.idle":"2024-12-12T04:26:37.694992Z","shell.execute_reply.started":"2024-12-11T23:48:33.076594Z","shell.execute_reply":"2024-12-12T04:26:37.694189Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='27880' max='27880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [27880/27880 4:38:01, Epoch 20/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>8.325200</td>\n      <td>8.105238</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>7.983500</td>\n      <td>7.811513</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>8.038100</td>\n      <td>7.713507</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>7.665200</td>\n      <td>7.572963</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>7.620300</td>\n      <td>7.537825</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>7.566500</td>\n      <td>7.519961</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>7.573300</td>\n      <td>7.506798</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>7.537900</td>\n      <td>7.500991</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>7.521800</td>\n      <td>7.497191</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>7.532300</td>\n      <td>7.491316</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>7.514800</td>\n      <td>7.490968</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>7.512000</td>\n      <td>7.487305</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>7.492300</td>\n      <td>7.487620</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>7.500500</td>\n      <td>7.484455</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>7.494400</td>\n      <td>7.483337</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>7.519800</td>\n      <td>7.482010</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>7.499900</td>\n      <td>7.480361</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>7.496500</td>\n      <td>7.481052</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>7.488600</td>\n      <td>7.480551</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>7.467000</td>\n      <td>7.480550</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=27880, training_loss=7.634449546956263, metrics={'train_runtime': 16683.2145, 'train_samples_per_second': 6.685, 'train_steps_per_second': 1.671, 'total_flos': 1.2245569565097984e+17, 'train_loss': 7.634449546956263, 'epoch': 20.0})"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# LoRA adaptasyonlarını kaydet\nmodel.save_pretrained(\"lora_finetuned_model\")\ntokenizer.save_pretrained(\"lora_finetuned_model\")\nprint(\"LoRA adaptasyonları başarıyla kaydedildi.\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T04:26:49.416805Z","iopub.execute_input":"2024-12-12T04:26:49.417205Z","iopub.status.idle":"2024-12-12T04:26:49.790105Z","shell.execute_reply.started":"2024-12-12T04:26:49.417173Z","shell.execute_reply":"2024-12-12T04:26:49.789289Z"}},"outputs":[{"name":"stdout","text":"LoRA adaptasyonları başarıyla kaydedildi.\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# LoRA adaptasyonlarını temel modelle birleştir\nmerged_model = model.merge_and_unload()\n\n# Birleştirilmiş tam modeli kaydet\nmerged_model.save_pretrained(\"full_finetuned_model\")\ntokenizer.save_pretrained(\"full_finetuned_model\")\nprint(\"Birleştirilmiş tam model başarıyla kaydedildi.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T04:27:00.128496Z","iopub.execute_input":"2024-12-12T04:27:00.128848Z","iopub.status.idle":"2024-12-12T04:27:05.887105Z","shell.execute_reply.started":"2024-12-12T04:27:00.128818Z","shell.execute_reply":"2024-12-12T04:27:05.886213Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Birleştirilmiş tam model başarıyla kaydedildi.\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Save the fine-tuned model\n#model.save_pretrained(\"fine_tuned_mbart_50_lora\")\n#tokenizer.save_pretrained(\"fine_tuned_mbart_50_lora\")\n\n#print(\"Fine-tuning complete. Model and tokenizer saved.\")\n\n# Eğitim tamamlandıktan sonra LoRA adaptasyonlarını kaydet\nmodel.save_pretrained(\"lora_mbart_50_finetuned_model\")\ntokenizer.save_pretrained(\"lora_mbart_50_finetuned_model\")\nprint(\"LoRA adaptasyonları kaydedildi.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# LoRA ve temel modeli birleştirip kaydet\nbase_model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/mbart-large-50\")\nlora_model = PeftModel.from_pretrained(base_model, \"lora_mbart_50_finetuned_model\")\nlora_model.save_pretrained(\"merged_model_lora_mbart_50\")\ntokenizer.save_pretrained(\"merged_model_lora_mbart_50\")\nprint(\"Birleştirilmiş model kaydedildi.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def generate_summary(model, tokenizer, text, max_length=150, min_length=30):\n    \"\"\"Haber metni için özet oluşturma.\"\"\"\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    input_ids = tokenizer.encode(text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n    summary_ids = model.generate(input_ids, max_length=max_length, min_length=min_length, num_beams=4, early_stopping=True)\n    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n\n# ROUGE Hesaplama Fonksiyonu\ndef evaluate_rouge(model, tokenizer):\n    print(\"Calculating ROUGE scores...\")\n    rouge_results = []\n\n    for article, reference_summary in zip(test_articles, test_summaries):\n        predicted_summary = generate_summary(model, tokenizer, article)\n        rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n        scores = rouge.score(predicted_summary, reference_summary)\n        rouge_results.append({\n            \"rouge1_f1\": scores['rouge1'].fmeasure,\n            \"rouge2_f1\": scores['rouge2'].fmeasure,\n            \"rougeL_f1\": scores['rougeL'].fmeasure\n        })\n\n    avg_rouge = {\n        key: sum(d[key] for d in rouge_results) / len(rouge_results)\n        for key in rouge_results[0]\n    }\n    print(f\"Average ROUGE Scores: {avg_rouge}\")\n\n# BLEU Hesaplama Fonksiyonu\ndef evaluate_bleu(model, tokenizer):\n    print(\"Calculating BLEU scores...\")\n    bleu_results = []\n\n    for article, reference_summary in zip(test_articles, test_summaries):\n        predicted_summary = generate_summary(model, tokenizer, article)\n        bleu_score = sacrebleu.sentence_bleu(predicted_summary, [reference_summary]).score\n        bleu_results.append(bleu_score)\n\n    avg_bleu = sum(bleu_results) / len(bleu_results)\n    print(f\"Average BLEU Score: {avg_bleu:.4f}\")\n\n# Corpus BLEU Hesaplama Fonksiyonu\ndef evaluate_corpus_bleu(model, tokenizer):\n    print(\"Calculating Corpus BLEU score...\")\n    predictions = []\n    references = []\n\n    for article, reference_summary in zip(test_articles, test_summaries):\n        predicted_summary = generate_summary(model, tokenizer, article)\n        predictions.append(predicted_summary)\n        references.append([reference_summary])  # SacreBLEU çoklu referansı destekler, bu yüzden liste içinde olmalı\n\n    bleu_score = sacrebleu.corpus_bleu(predictions, references).score\n    print(f\"Corpus BLEU Score: {bleu_score:.4f}\")\n\n# BERTScore Hesaplama Fonksiyonu\ndef evaluate_bertscore(model, tokenizer):\n    print(\"Calculating BERTScore...\")\n    bert_results = []\n\n    for article, reference_summary in zip(test_articles, test_summaries):\n        predicted_summary = generate_summary(model, tokenizer, article)\n        P, R, F1 = bert_score([predicted_summary], [reference_summary], lang=\"tr\")\n        bert_results.append(F1.mean().item())\n\n    avg_bert = sum(bert_results) / len(bert_results)\n    print(f\"Average BERTScore: {avg_bert:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T04:30:02.818290Z","iopub.execute_input":"2024-12-12T04:30:02.818708Z","iopub.status.idle":"2024-12-12T04:30:02.830697Z","shell.execute_reply.started":"2024-12-12T04:30:02.818677Z","shell.execute_reply":"2024-12-12T04:30:02.829640Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"import sacrebleu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T05:32:15.768542Z","iopub.execute_input":"2024-12-12T05:32:15.769341Z","iopub.status.idle":"2024-12-12T05:32:15.857597Z","shell.execute_reply.started":"2024-12-12T05:32:15.769291Z","shell.execute_reply":"2024-12-12T05:32:15.856716Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"evaluate_rouge(merged_model, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T04:30:20.744644Z","iopub.execute_input":"2024-12-12T04:30:20.746717Z","iopub.status.idle":"2024-12-12T04:47:47.668032Z","shell.execute_reply.started":"2024-12-12T04:30:20.745997Z","shell.execute_reply":"2024-12-12T04:47:47.667128Z"}},"outputs":[{"name":"stdout","text":"Calculating ROUGE scores...\nAverage ROUGE Scores: {'rouge1_f1': 0.5450307142660759, 'rouge2_f1': 0.44234999014827164, 'rougeL_f1': 0.5138451239983941}\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"evaluate_bleu(merged_model, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T05:32:19.948485Z","iopub.execute_input":"2024-12-12T05:32:19.949243Z","iopub.status.idle":"2024-12-12T05:49:17.146669Z","shell.execute_reply.started":"2024-12-12T05:32:19.949209Z","shell.execute_reply":"2024-12-12T05:49:17.145712Z"}},"outputs":[{"name":"stdout","text":"Calculating BLEU scores...\nAverage BLEU Score: 32.8252\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"evaluate_corpus_bleu(merged_model, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T06:00:23.918537Z","iopub.execute_input":"2024-12-12T06:00:23.919706Z","iopub.status.idle":"2024-12-12T06:18:11.225661Z","shell.execute_reply.started":"2024-12-12T06:00:23.919668Z","shell.execute_reply":"2024-12-12T06:18:11.224625Z"}},"outputs":[{"name":"stdout","text":"Calculating Corpus BLEU score...\nCorpus BLEU Score: 78.6645\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"evaluate_bertscore(merged_model, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-12T05:00:18.593747Z","iopub.execute_input":"2024-12-12T05:00:18.594478Z","iopub.status.idle":"2024-12-12T05:28:59.000019Z","shell.execute_reply.started":"2024-12-12T05:00:18.594443Z","shell.execute_reply":"2024-12-12T05:28:58.999049Z"}},"outputs":[{"name":"stdout","text":"Calculating BERTScore...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e052836e755445aaa2e070fa12476d0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"60264d5fc6a34cfa95b91c41ce09feec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/251k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d100fb7c0574714b2c53da43dd90457"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cc5be6bd24fe4e86853b2cd2ecfa5f06"}},"metadata":{}},{"name":"stdout","text":"Average BERTScore: 0.7756\n","output_type":"stream"}],"execution_count":17}]}