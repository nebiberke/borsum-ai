{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9803653,"sourceType":"datasetVersion","datasetId":6008839}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pandas torch transformers datasets scikit-learn rouge-score bert-score","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-02T14:53:22.894471Z","iopub.execute_input":"2024-12-02T14:53:22.894837Z","iopub.status.idle":"2024-12-02T14:53:34.127848Z","shell.execute_reply.started":"2024-12-02T14:53:22.894796Z","shell.execute_reply":"2024-12-02T14:53:34.126797Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nCollecting rouge-score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting bert-score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert-score) (3.7.5)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.4.5)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (10.3.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rouge-score\n  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=26d7ca1626e9df264c695490ef92d8e8304c5c6a5b132989787989d797f640ef\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge-score\nInstalling collected packages: rouge-score, bert-score\nSuccessfully installed bert-score-0.3.13 rouge-score-0.1.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport torch\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments\nfrom datasets import Dataset, DatasetDict\nfrom sklearn.model_selection import train_test_split\nfrom rouge_score import rouge_scorer\nfrom bert_score import score as bert_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T14:53:36.871273Z","iopub.execute_input":"2024-12-02T14:53:36.872155Z","iopub.status.idle":"2024-12-02T14:53:54.777933Z","shell.execute_reply.started":"2024-12-02T14:53:36.872116Z","shell.execute_reply":"2024-12-02T14:53:54.777175Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Load the dataset\ninput_path = '/kaggle/input/eco-news-toplu/eco_news_cleaned3.csv'\nif not os.path.exists(input_path):\n    raise FileNotFoundError(f\"File not found: {input_path}\")\n\n# Read CSV file\ndf = pd.read_csv(input_path)\n\n# Drop rows with NaN values in 'icerik' or 'ozet' columns\ndf = df.dropna(subset=['icerik', 'ozet'])\n\n# Separate articles and summaries\narticles = df['icerik'].tolist()\nsummaries = df['ozet'].tolist()\n\n# Veriyi ilk olarak train ve test olarak ayırıyoruz\ntrain_articles, test_articles, train_summaries, test_summaries = train_test_split(\n    articles, summaries, test_size=0.2, random_state=42\n)\n\n# Train setini bir daha ayırarak train ve validation setlerini oluşturuyoruz\ntrain_articles, val_articles, train_summaries, val_summaries = train_test_split(\n    train_articles, train_summaries, test_size=0.1, random_state=42\n)\n\nprint(f\"Train set size: {len(train_articles)}\")\nprint(f\"Validation set size: {len(val_articles)}\")\nprint(f\"Test set size: {len(test_articles)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T14:53:57.059809Z","iopub.execute_input":"2024-12-02T14:53:57.060459Z","iopub.status.idle":"2024-12-02T14:53:57.755524Z","shell.execute_reply.started":"2024-12-02T14:53:57.060425Z","shell.execute_reply":"2024-12-02T14:53:57.754664Z"}},"outputs":[{"name":"stdout","text":"Train set size: 5576\nValidation set size: 620\nTest set size: 1550\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Her bir seti Hugging Face Dataset formatına dönüştürme\ntrain_data = {'article': train_articles, 'summary': train_summaries}\nval_data = {'article': val_articles, 'summary': val_summaries}\ntest_data = {'article': test_articles, 'summary': test_summaries}\n\ntrain_dataset = Dataset.from_dict(train_data)\nval_dataset = Dataset.from_dict(val_data)\ntest_dataset = Dataset.from_dict(test_data)\n\n# DatasetDict formatında birleştirme\ndataset = DatasetDict({\n    'train': train_dataset,\n    'validation': val_dataset,\n    'test': test_dataset\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T14:54:00.062020Z","iopub.execute_input":"2024-12-02T14:54:00.062733Z","iopub.status.idle":"2024-12-02T14:54:00.387033Z","shell.execute_reply.started":"2024-12-02T14:54:00.062685Z","shell.execute_reply":"2024-12-02T14:54:00.386244Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Load tokenizer and model\nmodel_name = 'google/flan-t5-base'\ntokenizer = T5Tokenizer.from_pretrained(model_name)\nmodel = T5ForConditionalGeneration.from_pretrained(model_name)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T14:54:02.401212Z","iopub.execute_input":"2024-12-02T14:54:02.401555Z","iopub.status.idle":"2024-12-02T14:54:09.786825Z","shell.execute_reply.started":"2024-12-02T14:54:02.401525Z","shell.execute_reply":"2024-12-02T14:54:09.785643Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae4c6a1776414180a0707b9a8d6d5c90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9c21ff9e5ff45e1a309f9f8995c72e9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3606f44af65948c39c44e2d1899a3cba"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"033a07cc1c29496b984fd8f2c1adcd6e"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4699d383100e47c08aae2add7e9ab521"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb0591208a7e4c989a1ef44b304e744d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e685b7eaf7c1449e9eb3deacf89c4323"}},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"def preprocess_data(examples):\n    inputs = [f\"Özetle: {article}\" for article in examples[\"article\"]]\n    targets = examples['summary']\n    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n    labels = tokenizer(targets, max_length=150, truncation=True, padding=\"max_length\")\n    \n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n    \ntokenized_dataset = dataset.map(preprocess_data, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T14:54:21.527926Z","iopub.execute_input":"2024-12-02T14:54:21.528286Z","iopub.status.idle":"2024-12-02T14:54:54.018454Z","shell.execute_reply.started":"2024-12-02T14:54:21.528256Z","shell.execute_reply":"2024-12-02T14:54:54.017661Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/5576 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea1711a707d54b6a8c45657809d0e3bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/620 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"49accaf3936c4aa7858260e368a1b966"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1550 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d2f88388cfd4d9d94f0e6b7763bf7b6"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir='./results',\n    eval_strategy=\"epoch\",\n    save_strategy=\"no\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    num_train_epochs=20,\n    weight_decay=0.01,\n    predict_with_generate=True,\n    logging_dir='./logs',\n    report_to=\"none\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T14:55:09.717385Z","iopub.execute_input":"2024-12-02T14:55:09.717763Z","iopub.status.idle":"2024-12-02T14:55:09.804247Z","shell.execute_reply.started":"2024-12-02T14:55:09.717722Z","shell.execute_reply":"2024-12-02T14:55:09.803294Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Initialize Seq2SeqTrainer\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"validation\"],\n    tokenizer=tokenizer,\n)\n\n# Start training\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T14:55:12.193291Z","iopub.execute_input":"2024-12-02T14:55:12.194169Z","iopub.status.idle":"2024-12-02T18:24:38.768316Z","shell.execute_reply.started":"2024-12-02T14:55:12.194135Z","shell.execute_reply":"2024-12-02T18:24:38.767444Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='27880' max='27880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [27880/27880 3:29:23, Epoch 20/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.552100</td>\n      <td>0.432722</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.459400</td>\n      <td>0.389785</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.416000</td>\n      <td>0.377458</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>0.397500</td>\n      <td>0.364673</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>0.392500</td>\n      <td>0.353719</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>0.381000</td>\n      <td>0.345619</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>0.370500</td>\n      <td>0.342900</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>0.349000</td>\n      <td>0.336619</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>0.342800</td>\n      <td>0.336293</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>0.328700</td>\n      <td>0.333982</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>0.338200</td>\n      <td>0.328555</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>0.331500</td>\n      <td>0.330435</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>0.327200</td>\n      <td>0.328674</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>0.310600</td>\n      <td>0.327123</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>0.309100</td>\n      <td>0.325142</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>0.298400</td>\n      <td>0.324913</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>0.297900</td>\n      <td>0.323281</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>0.298600</td>\n      <td>0.322430</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>0.293800</td>\n      <td>0.323932</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.320300</td>\n      <td>0.323115</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=27880, training_loss=0.392600905365034, metrics={'train_runtime': 12564.873, 'train_samples_per_second': 8.876, 'train_steps_per_second': 2.219, 'total_flos': 7.636413994500096e+16, 'train_loss': 0.392600905365034, 'epoch': 20.0})"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"# Save the fine-tuned model\nmodel.save_pretrained(\"fine_tuned_flan-t5-yeni\")\ntokenizer.save_pretrained(\"fine_tuned_flan-t5-yeni\")\n\nprint(\"Fine-tuning complete. Model and tokenizer saved.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T18:58:51.836950Z","iopub.execute_input":"2024-12-02T18:58:51.837777Z","iopub.status.idle":"2024-12-02T18:58:54.206686Z","shell.execute_reply.started":"2024-12-02T18:58:51.837711Z","shell.execute_reply":"2024-12-02T18:58:54.205812Z"}},"outputs":[{"name":"stdout","text":"Fine-tuning complete. Model and tokenizer saved.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!pip install sacrebleu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T19:53:59.540465Z","iopub.execute_input":"2024-12-02T19:53:59.540813Z","iopub.status.idle":"2024-12-02T19:54:07.859589Z","shell.execute_reply.started":"2024-12-02T19:53:59.540783Z","shell.execute_reply":"2024-12-02T19:54:07.858519Z"}},"outputs":[{"name":"stdout","text":"Collecting sacrebleu\n  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (2024.5.15)\nRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (1.26.4)\nRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.3.0)\nDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-3.0.0-py3-none-any.whl (19 kB)\nInstalling collected packages: portalocker, sacrebleu\nSuccessfully installed portalocker-3.0.0 sacrebleu-2.4.3\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"def generate_summary(model, tokenizer, text, max_length=150, min_length=30):\n    \"\"\"Haber metni için özet oluşturma.\"\"\"\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    input_ids = tokenizer.encode(text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n    summary_ids = model.generate(input_ids, max_length=max_length, min_length=min_length, num_beams=4, early_stopping=True)\n    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T19:02:03.391382Z","iopub.execute_input":"2024-12-02T19:02:03.391748Z","iopub.status.idle":"2024-12-02T19:02:03.397231Z","shell.execute_reply.started":"2024-12-02T19:02:03.391705Z","shell.execute_reply":"2024-12-02T19:02:03.396290Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# ROUGE Hesaplama Fonksiyonu\ndef evaluate_rouge(model, tokenizer):\n    print(\"Calculating ROUGE scores...\")\n    rouge_results = []\n\n    for article, reference_summary in zip(test_articles, test_summaries):\n        predicted_summary = generate_summary(model, tokenizer, article)\n        rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n        scores = rouge.score(predicted_summary, reference_summary)\n        rouge_results.append({\n            \"rouge1_f1\": scores['rouge1'].fmeasure,\n            \"rouge2_f1\": scores['rouge2'].fmeasure,\n            \"rougeL_f1\": scores['rougeL'].fmeasure\n        })\n\n    avg_rouge = {\n        key: sum(d[key] for d in rouge_results) / len(rouge_results)\n        for key in rouge_results[0]\n    }\n    print(f\"Average ROUGE Scores: {avg_rouge}\")\n\n# BLEU Hesaplama Fonksiyonu\ndef evaluate_bleu(model, tokenizer):\n    print(\"Calculating BLEU scores...\")\n    bleu_results = []\n\n    for article, reference_summary in zip(test_articles, test_summaries):\n        predicted_summary = generate_summary(model, tokenizer, article)\n        bleu_score = sacrebleu.sentence_bleu(predicted_summary, [reference_summary]).score\n        bleu_results.append(bleu_score)\n\n    avg_bleu = sum(bleu_results) / len(bleu_results)\n    print(f\"Average BLEU Score: {avg_bleu:.4f}\")\n    # Corpus BLEU Hesaplama Fonksiyonu\n\ndef evaluate_corpus_bleu(model, tokenizer):\n    print(\"Calculating Corpus BLEU score...\")\n    predictions = []\n    references = []\n\n    for article, reference_summary in zip(test_articles, test_summaries):\n        predicted_summary = generate_summary(model, tokenizer, article)\n        predictions.append(predicted_summary)\n        references.append([reference_summary])  # SacreBLEU çoklu referansı destekler, bu yüzden liste içinde olmalı\n\n    bleu_score = sacrebleu.corpus_bleu(predictions, references).score\n    print(f\"Corpus BLEU Score: {bleu_score:.4f}\")\n\n# BERTScore Hesaplama Fonksiyonu\ndef evaluate_bertscore(model, tokenizer):\n    print(\"Calculating BERTScore...\")\n    bert_results = []\n\n    for article, reference_summary in zip(test_articles, test_summaries):\n        predicted_summary = generate_summary(model, tokenizer, article)\n        P, R, F1 = bert_score([predicted_summary], [reference_summary], lang=\"tr\")\n        bert_results.append(F1.mean().item())\n\n    avg_bert = sum(bert_results) / len(bert_results)\n    print(f\"Average BERTScore: {avg_bert:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T19:02:05.789080Z","iopub.execute_input":"2024-12-02T19:02:05.789385Z","iopub.status.idle":"2024-12-02T19:02:05.798901Z","shell.execute_reply.started":"2024-12-02T19:02:05.789352Z","shell.execute_reply":"2024-12-02T19:02:05.798015Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"evaluate_rouge(model, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T19:02:11.008147Z","iopub.execute_input":"2024-12-02T19:02:11.008449Z","iopub.status.idle":"2024-12-02T19:43:35.883516Z","shell.execute_reply.started":"2024-12-02T19:02:11.008424Z","shell.execute_reply":"2024-12-02T19:43:35.882584Z"}},"outputs":[{"name":"stdout","text":"Calculating ROUGE scores...\nAverage ROUGE Scores: {'rouge1_f1': 0.5448951185094446, 'rouge2_f1': 0.41971176557795264, 'rougeL_f1': 0.5222822915783296}\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import sacrebleu\nevaluate_bleu(model, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T19:54:26.094434Z","iopub.execute_input":"2024-12-02T19:54:26.094833Z","iopub.status.idle":"2024-12-02T20:36:09.118080Z","shell.execute_reply.started":"2024-12-02T19:54:26.094799Z","shell.execute_reply":"2024-12-02T20:36:09.117127Z"}},"outputs":[{"name":"stdout","text":"Calculating BLEU scores...\nAverage BLEU Score: 24.7775\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"evaluate_corpus_bleu(model, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T21:41:46.936767Z","iopub.execute_input":"2024-12-02T21:41:46.937532Z","iopub.status.idle":"2024-12-02T22:23:27.112430Z","shell.execute_reply.started":"2024-12-02T21:41:46.937500Z","shell.execute_reply":"2024-12-02T22:23:27.111514Z"}},"outputs":[{"name":"stdout","text":"Calculating Corpus BLEU score...\nCorpus BLEU Score: 50.3175\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"evaluate_bertscore(model, tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-02T20:48:21.952549Z","iopub.execute_input":"2024-12-02T20:48:21.953677Z","iopub.status.idle":"2024-12-02T21:41:16.762999Z","shell.execute_reply.started":"2024-12-02T20:48:21.953641Z","shell.execute_reply":"2024-12-02T21:41:16.762044Z"}},"outputs":[{"name":"stdout","text":"Calculating BERTScore...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6d6dd800b194631b3f7b5352ddb81db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"245c592f42214a348a5a5b4f069e9116"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/251k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6bc4cde88ef4c16896c397dfbb41605"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3083ddc076034a05b9553de2baa5a242"}},"metadata":{}},{"name":"stdout","text":"Average BERTScore: 0.7255\n","output_type":"stream"}],"execution_count":17}]}