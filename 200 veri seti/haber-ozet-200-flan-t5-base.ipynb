{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-10T19:13:49.739141Z",
     "iopub.status.busy": "2024-12-10T19:13:49.738153Z",
     "iopub.status.idle": "2024-12-10T19:14:02.054658Z",
     "shell.execute_reply": "2024-12-10T19:14:02.053587Z",
     "shell.execute_reply.started": "2024-12-10T19:13:49.739092Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.1.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\n",
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score) (3.2.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert-score) (3.7.5)\n",
      "Collecting portalocker (from sacrebleu)\n",
      "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (10.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=37df280542857d39cb7c41be923fc49ee7957c7f4f48d20e6a4c2aaf7d622caf\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: portalocker, sacrebleu, rouge-score, bert-score\n",
      "Successfully installed bert-score-0.3.13 portalocker-3.0.0 rouge-score-0.1.2 sacrebleu-2.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas torch transformers datasets scikit-learn rouge-score bert-score sacrebleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VERİ SETİNİ HAZIRLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T19:14:05.819706Z",
     "iopub.status.busy": "2024-12-10T19:14:05.819290Z",
     "iopub.status.idle": "2024-12-10T19:14:26.644794Z",
     "shell.execute_reply": "2024-12-10T19:14:26.644067Z",
     "shell.execute_reply.started": "2024-12-10T19:14:05.819667Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score as bert_score\n",
    "import sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T19:14:31.067811Z",
     "iopub.status.busy": "2024-12-10T19:14:31.066846Z",
     "iopub.status.idle": "2024-12-10T19:14:31.115283Z",
     "shell.execute_reply": "2024-12-10T19:14:31.114458Z",
     "shell.execute_reply.started": "2024-12-10T19:14:31.067773Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 172\n",
      "Validation set size: 20\n",
      "Test set size: 48\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "input_path = '/kaggle/input/eco-news-me/haberler.csv'\n",
    "if not os.path.exists(input_path):\n",
    "    raise FileNotFoundError(f\"File not found: {input_path}\")\n",
    "\n",
    "# Read CSV file\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# Drop rows with NaN values in 'icerik' or 'ozet' columns\n",
    "df = df.dropna(subset=['icerik', 'ozet'])\n",
    "\n",
    "# Separate articles and summaries\n",
    "articles = df['icerik'].tolist()\n",
    "summaries = df['ozet'].tolist()\n",
    "\n",
    "# Split the dataset into train, validation and test sets\n",
    "train_articles, test_articles, train_summaries, test_summaries = train_test_split(\n",
    "    articles, summaries, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Split the train set into train and validation sets\n",
    "train_articles, val_articles, train_summaries, val_summaries = train_test_split(\n",
    "    train_articles, train_summaries, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train set size: {len(train_articles)}\")\n",
    "print(f\"Validation set size: {len(val_articles)}\")\n",
    "print(f\"Test set size: {len(test_articles)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T19:14:33.766484Z",
     "iopub.status.busy": "2024-12-10T19:14:33.765908Z",
     "iopub.status.idle": "2024-12-10T19:14:33.802197Z",
     "shell.execute_reply": "2024-12-10T19:14:33.801518Z",
     "shell.execute_reply.started": "2024-12-10T19:14:33.766447Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Tokenizer\n",
    "train_data = {'article': train_articles, 'summary': train_summaries}\n",
    "val_data = {'article': val_articles, 'summary': val_summaries}\n",
    "test_data = {'article': test_articles, 'summary': test_summaries}\n",
    "\n",
    "train_dataset = Dataset.from_dict(train_data)\n",
    "val_dataset = Dataset.from_dict(val_data)\n",
    "test_dataset = Dataset.from_dict(test_data)\n",
    "\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T19:14:36.430401Z",
     "iopub.status.busy": "2024-12-10T19:14:36.429560Z",
     "iopub.status.idle": "2024-12-10T19:14:42.539508Z",
     "shell.execute_reply": "2024-12-10T19:14:42.538608Z",
     "shell.execute_reply.started": "2024-12-10T19:14:36.430364Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de15d33e8f864ddd85bbe7d1e626adc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66ad4758ef4c4afbb5f023420bec6863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bee4fb74e2c4b7393598ae2223fb92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ced310d79035435399611dc0ea718d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "356ffad22f3e40feaf891f22152d8779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33dcb3e196f34338a21b01d0a1c7c66f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2a8e3cd6e6f4dd9a2eb2a3f6b59f470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the dataset\n",
    "model_name = 'google/flan-t5-base'\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T19:14:48.784023Z",
     "iopub.status.busy": "2024-12-10T19:14:48.783669Z",
     "iopub.status.idle": "2024-12-10T19:14:48.788449Z",
     "shell.execute_reply": "2024-12-10T19:14:48.787450Z",
     "shell.execute_reply.started": "2024-12-10T19:14:48.783992Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the data collator\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T19:14:50.938361Z",
     "iopub.status.busy": "2024-12-10T19:14:50.937253Z",
     "iopub.status.idle": "2024-12-10T19:14:51.791804Z",
     "shell.execute_reply": "2024-12-10T19:14:51.790921Z",
     "shell.execute_reply.started": "2024-12-10T19:14:50.938306Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2867e966677642b9b115b0462924cde4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/172 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124b16acf25b4bc5aa6a031b25d2df86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ff62ef1041454ebd70922a17f4edcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/48 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "def preprocess_data(examples):\n",
    "    inputs = [f\"Özetle: {article}\" for article in examples[\"article\"]]\n",
    "    targets = examples['summary']\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
    "    labels = tokenizer(targets, max_length=150, truncation=True, padding=\"max_length\")\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "    \n",
    "tokenized_dataset = dataset.map(preprocess_data, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELİ EĞİT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T19:14:56.377608Z",
     "iopub.status.busy": "2024-12-10T19:14:56.377253Z",
     "iopub.status.idle": "2024-12-10T19:14:56.500141Z",
     "shell.execute_reply": "2024-12-10T19:14:56.499426Z",
     "shell.execute_reply.started": "2024-12-10T19:14:56.377568Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define the evaluation metric\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./results',\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=100,\n",
    "    weight_decay=0.01,\n",
    "    predict_with_generate=True,\n",
    "    logging_dir='./logs',\n",
    "    report_to=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T19:14:59.538861Z",
     "iopub.status.busy": "2024-12-10T19:14:59.537852Z",
     "iopub.status.idle": "2024-12-10T19:47:32.582413Z",
     "shell.execute_reply": "2024-12-10T19:47:32.581640Z",
     "shell.execute_reply.started": "2024-12-10T19:14:59.538823Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4300' max='4300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4300/4300 32:30, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.166616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.536340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.822128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.679060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.522172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.401485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.331476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.305739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.285748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.270098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.265663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.115800</td>\n",
       "      <td>1.259606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.115800</td>\n",
       "      <td>1.254724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.115800</td>\n",
       "      <td>1.241169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.115800</td>\n",
       "      <td>1.244350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.115800</td>\n",
       "      <td>1.245981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.115800</td>\n",
       "      <td>1.234065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.115800</td>\n",
       "      <td>1.241038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.115800</td>\n",
       "      <td>1.238615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.115800</td>\n",
       "      <td>1.241860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.115800</td>\n",
       "      <td>1.239881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.115800</td>\n",
       "      <td>1.238407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.115800</td>\n",
       "      <td>1.235090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>1.249874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>1.245611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>1.244961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>1.244329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>1.249318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>1.261940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>1.248990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>1.252517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>1.253345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>1.253339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.005000</td>\n",
       "      <td>1.247131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.839500</td>\n",
       "      <td>1.250898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.839500</td>\n",
       "      <td>1.258468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.839500</td>\n",
       "      <td>1.254565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.839500</td>\n",
       "      <td>1.264597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.839500</td>\n",
       "      <td>1.270670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.839500</td>\n",
       "      <td>1.265507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.839500</td>\n",
       "      <td>1.271271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.839500</td>\n",
       "      <td>1.275170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.839500</td>\n",
       "      <td>1.275532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.839500</td>\n",
       "      <td>1.273746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.839500</td>\n",
       "      <td>1.278297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.839500</td>\n",
       "      <td>1.279605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.736600</td>\n",
       "      <td>1.280592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.736600</td>\n",
       "      <td>1.282315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.736600</td>\n",
       "      <td>1.281720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.736600</td>\n",
       "      <td>1.276579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.736600</td>\n",
       "      <td>1.286393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.736600</td>\n",
       "      <td>1.290532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.736600</td>\n",
       "      <td>1.292128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.736600</td>\n",
       "      <td>1.289240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.736600</td>\n",
       "      <td>1.295926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.736600</td>\n",
       "      <td>1.301907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.736600</td>\n",
       "      <td>1.302826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.736600</td>\n",
       "      <td>1.301450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.669200</td>\n",
       "      <td>1.306116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.669200</td>\n",
       "      <td>1.306932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.669200</td>\n",
       "      <td>1.308704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.669200</td>\n",
       "      <td>1.311588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.669200</td>\n",
       "      <td>1.311477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.669200</td>\n",
       "      <td>1.317013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.669200</td>\n",
       "      <td>1.317184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.669200</td>\n",
       "      <td>1.320856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.669200</td>\n",
       "      <td>1.315549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.669200</td>\n",
       "      <td>1.320345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.669200</td>\n",
       "      <td>1.322004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.620200</td>\n",
       "      <td>1.329373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.620200</td>\n",
       "      <td>1.329957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.620200</td>\n",
       "      <td>1.330343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.620200</td>\n",
       "      <td>1.326685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.620200</td>\n",
       "      <td>1.333926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.620200</td>\n",
       "      <td>1.333244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.620200</td>\n",
       "      <td>1.330925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.620200</td>\n",
       "      <td>1.337274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.620200</td>\n",
       "      <td>1.345249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.620200</td>\n",
       "      <td>1.334136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.620200</td>\n",
       "      <td>1.335214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.620200</td>\n",
       "      <td>1.335377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.586200</td>\n",
       "      <td>1.338896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.586200</td>\n",
       "      <td>1.338898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.586200</td>\n",
       "      <td>1.341290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.586200</td>\n",
       "      <td>1.336701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.586200</td>\n",
       "      <td>1.338237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.586200</td>\n",
       "      <td>1.343318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.586200</td>\n",
       "      <td>1.345809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.586200</td>\n",
       "      <td>1.343876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.586200</td>\n",
       "      <td>1.343768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.586200</td>\n",
       "      <td>1.343362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.586200</td>\n",
       "      <td>1.341624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.586200</td>\n",
       "      <td>1.342726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.568600</td>\n",
       "      <td>1.342239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.568600</td>\n",
       "      <td>1.343841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.568600</td>\n",
       "      <td>1.345668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.568600</td>\n",
       "      <td>1.346774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.568600</td>\n",
       "      <td>1.347135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.568600</td>\n",
       "      <td>1.347659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.568600</td>\n",
       "      <td>1.347808</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4300, training_loss=0.8692446083246276, metrics={'train_runtime': 1952.1654, 'train_samples_per_second': 8.811, 'train_steps_per_second': 2.203, 'total_flos': 1.17778264621056e+16, 'train_loss': 0.8692446083246276, 'epoch': 100.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"fine_tuned_flan-t5-200\")\n",
    "tokenizer.save_pretrained(\"fine_tuned_flan-t5-200\")\n",
    "\n",
    "print(\"Fine-tuning complete. Model and tokenizer saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T20:08:04.950881Z",
     "iopub.status.busy": "2024-12-10T20:08:04.949951Z",
     "iopub.status.idle": "2024-12-10T20:08:04.956593Z",
     "shell.execute_reply": "2024-12-10T20:08:04.955449Z",
     "shell.execute_reply.started": "2024-12-10T20:08:04.950837Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_summary(model, tokenizer, text, max_length=150, min_length=30):\n",
    "    \"\"\"Haber metni için özet oluşturma.\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    text = f'Özetle {text}'\n",
    "    input_ids = tokenizer.encode(text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "    summary_ids = model.generate(input_ids, max_length=max_length, min_length=min_length, num_beams=4, early_stopping=True)\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T19:55:27.553836Z",
     "iopub.status.busy": "2024-12-10T19:55:27.553423Z",
     "iopub.status.idle": "2024-12-10T19:55:27.564466Z",
     "shell.execute_reply": "2024-12-10T19:55:27.563344Z",
     "shell.execute_reply.started": "2024-12-10T19:55:27.553798Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ROUGE Hesaplama Fonksiyonu\n",
    "def evaluate_rouge(model, tokenizer):\n",
    "    print(\"Calculating ROUGE scores...\")\n",
    "    rouge_results = []\n",
    "\n",
    "    for article, reference_summary in zip(test_articles, test_summaries):\n",
    "        predicted_summary = generate_summary(model, tokenizer, article)\n",
    "        rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "        scores = rouge.score(predicted_summary, reference_summary)\n",
    "        rouge_results.append({\n",
    "            \"rouge1_f1\": scores['rouge1'].fmeasure,\n",
    "            \"rouge2_f1\": scores['rouge2'].fmeasure,\n",
    "            \"rougeL_f1\": scores['rougeL'].fmeasure\n",
    "        })\n",
    "\n",
    "    avg_rouge = {\n",
    "        key: sum(d[key] for d in rouge_results) / len(rouge_results)\n",
    "        for key in rouge_results[0]\n",
    "    }\n",
    "    print(f\"Average ROUGE Scores: {avg_rouge}\")\n",
    "\n",
    "# BLEU Hesaplama Fonksiyonu\n",
    "def evaluate_bleu(model, tokenizer):\n",
    "    print(\"Calculating BLEU scores...\")\n",
    "    bleu_results = []\n",
    "\n",
    "    for article, reference_summary in zip(test_articles, test_summaries):\n",
    "        predicted_summary = generate_summary(model, tokenizer, article)\n",
    "        bleu_score = sacrebleu.sentence_bleu(predicted_summary, [reference_summary]).score\n",
    "        bleu_results.append(bleu_score)\n",
    "\n",
    "    avg_bleu = sum(bleu_results) / len(bleu_results)\n",
    "    print(f\"Average BLEU Score: {avg_bleu:.4f}\")\n",
    "    # Corpus BLEU Hesaplama Fonksiyonu\n",
    "\n",
    "def evaluate_corpus_bleu(model, tokenizer):\n",
    "    print(\"Calculating Corpus BLEU score...\")\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    for article, reference_summary in zip(test_articles, test_summaries):\n",
    "        predicted_summary = generate_summary(model, tokenizer, article)\n",
    "        predictions.append(predicted_summary)\n",
    "        references.append([reference_summary])  # SacreBLEU çoklu referansı destekler, bu yüzden liste içinde olmalı\n",
    "\n",
    "    bleu_score = sacrebleu.corpus_bleu(predictions, references).score\n",
    "    print(f\"Corpus BLEU Score: {bleu_score:.4f}\")\n",
    "\n",
    "# BERTScore Hesaplama Fonksiyonu\n",
    "def evaluate_bertscore(model, tokenizer):\n",
    "    print(\"Calculating BERTScore...\")\n",
    "    bert_results = []\n",
    "\n",
    "    for article, reference_summary in zip(test_articles, test_summaries):\n",
    "        predicted_summary = generate_summary(model, tokenizer, article)\n",
    "        P, R, F1 = bert_score([predicted_summary], [reference_summary], lang=\"tr\")\n",
    "        bert_results.append(F1.mean().item())\n",
    "\n",
    "    avg_bert = sum(bert_results) / len(bert_results)\n",
    "    print(f\"Average BERTScore: {avg_bert:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T19:55:30.902542Z",
     "iopub.status.busy": "2024-12-10T19:55:30.902134Z",
     "iopub.status.idle": "2024-12-10T19:57:51.431488Z",
     "shell.execute_reply": "2024-12-10T19:57:51.430566Z",
     "shell.execute_reply.started": "2024-12-10T19:55:30.902489Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating ROUGE scores...\n",
      "Average ROUGE Scores: {'rouge1_f1': 0.3370354590904768, 'rouge2_f1': 0.16195183920750106, 'rougeL_f1': 0.2819354606201934}\n"
     ]
    }
   ],
   "source": [
    "evaluate_rouge(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T19:58:35.886431Z",
     "iopub.status.busy": "2024-12-10T19:58:35.885706Z",
     "iopub.status.idle": "2024-12-10T20:03:11.365497Z",
     "shell.execute_reply": "2024-12-10T20:03:11.364590Z",
     "shell.execute_reply.started": "2024-12-10T19:58:35.886396Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating BLEU scores...\n",
      "Average BLEU Score: 7.0374\n",
      "Calculating Corpus BLEU score...\n",
      "Corpus BLEU Score: 18.9022\n"
     ]
    }
   ],
   "source": [
    "evaluate_bleu(model, tokenizer)\n",
    "evaluate_corpus_bleu(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T20:03:38.243635Z",
     "iopub.status.busy": "2024-12-10T20:03:38.243255Z",
     "iopub.status.idle": "2024-12-10T20:06:19.333496Z",
     "shell.execute_reply": "2024-12-10T20:06:19.332596Z",
     "shell.execute_reply.started": "2024-12-10T20:03:38.243598Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating BERTScore...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57442e8726dc4edfb509f83558cf97e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c04811e6d923464680e160e9db765a4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "727075c9d195409982b79b0ba57f5043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/251k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dfb3ae170d84f0e98c8f1e4a0f06f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BERTScore: 0.5884\n"
     ]
    }
   ],
   "source": [
    "evaluate_bertscore(model, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Veri Setinden Random Örnek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T20:08:10.499570Z",
     "iopub.status.busy": "2024-12-10T20:08:10.499157Z",
     "iopub.status.idle": "2024-12-10T20:08:12.758480Z",
     "shell.execute_reply": "2024-12-10T20:08:12.757573Z",
     "shell.execute_reply.started": "2024-12-10T20:08:10.499518Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ Rastgele Seçilen Haber 8 ------\n",
      "--- Orijinal Metin ---\n",
      "Otokar Otomotiv ve Savunma Sanayi (OTKAR), bugün Kamuyu Aydınlatma Platformu’na gönderdiği açıklamada temettü kararı hakkında bilgi verdi. Açıklamada, şirketin 2023 yılında 1.9 milyar lira net dönem karı elde ettiği belirtilerek ortaklara ödenecek toplam kar payı tutarının 720 milyon lira olduğu kaydedildi. Otokar'ın hisse başına 5 lira 40 kuruş temettü ödemesinin kararlaştırıldığı ifade edildi. Temettünün dağıtılacağı tarih henüz açıklanmadı.\n",
      "--- Modelin Oluşturduğu Özet ---\n",
      "Otokar, 2023 ylnda 1.9 milyar TL net dönem kar elde ettii belirtilerek ortaklara ödenecek toplam kar pay tutarn 720 milyon TL oldu. Temettü ödemesinin datlacak.\n",
      "--- Gerçek Özet ---\n",
      "Otokar, 2023 yılında elde ettiği 1,9 milyar TL net kar sonrası yatırımcılarına hisse başına 5,40 TL temettü ödeyeceğini duyurdu. Toplamda 720 milyon TL kar payı dağıtılacak, ancak dağıtım tarihi henüz açıklanmadı.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Rastgele bir örnek seçme\n",
    "random_index = random.randint(0, len(test_articles) - 1)\n",
    "article = test_articles[random_index]\n",
    "reference_summary = test_summaries[random_index]\n",
    "predicted_summary = generate_summary(model, tokenizer, article)\n",
    "\n",
    "# Seçilen rastgele örneği yazdırma\n",
    "print(f\"\\n------ Rastgele Seçilen Haber {random_index + 1} ------\")\n",
    "print(f\"--- Orijinal Metin ---\\n{article}\")\n",
    "print(f\"--- Modelin Oluşturduğu Özet ---\\n{predicted_summary}\")\n",
    "print(f\"--- Gerçek Özet ---\\n{reference_summary}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5947269,
     "sourceId": 9720602,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6205643,
     "sourceId": 10068647,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
