{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-11T11:23:26.390742Z",
     "iopub.status.busy": "2024-12-11T11:23:26.390359Z",
     "iopub.status.idle": "2024-12-11T11:23:38.884834Z",
     "shell.execute_reply": "2024-12-11T11:23:38.883819Z",
     "shell.execute_reply.started": "2024-12-11T11:23:26.390706Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.1.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\n",
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score) (3.2.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert-score) (3.7.5)\n",
      "Collecting portalocker (from sacrebleu)\n",
      "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (10.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=d3a605fe84843c972503a486890818eca79115e4d04ae7ee62ed5a90bf2191d0\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: portalocker, sacrebleu, rouge-score, bert-score\n",
      "Successfully installed bert-score-0.3.13 portalocker-3.0.0 rouge-score-0.1.2 sacrebleu-2.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas torch transformers datasets scikit-learn rouge-score bert-score sacrebleu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VERİ SETİNİ HAZIRLA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T11:23:49.156979Z",
     "iopub.status.busy": "2024-12-11T11:23:49.156080Z",
     "iopub.status.idle": "2024-12-11T11:24:09.357499Z",
     "shell.execute_reply": "2024-12-11T11:24:09.356761Z",
     "shell.execute_reply.started": "2024-12-11T11:23:49.156942Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import MBartForConditionalGeneration, MBart50TokenizerFast, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score as bert_score\n",
    "import sacrebleu\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T11:24:17.052876Z",
     "iopub.status.busy": "2024-12-11T11:24:17.052183Z",
     "iopub.status.idle": "2024-12-11T11:24:17.109214Z",
     "shell.execute_reply": "2024-12-11T11:24:17.108324Z",
     "shell.execute_reply.started": "2024-12-11T11:24:17.052842Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 172\n",
      "Validation set size: 20\n",
      "Test set size: 48\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "input_path = '/kaggle/input/eco-news-me/haberler.csv'\n",
    "if not os.path.exists(input_path):\n",
    "    raise FileNotFoundError(f\"File not found: {input_path}\")\n",
    "\n",
    "# Read CSV file\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# Drop rows with NaN values in 'icerik' or 'ozet' columns\n",
    "df = df.dropna(subset=['icerik', 'ozet'])\n",
    "\n",
    "# Separate articles and summaries\n",
    "articles = df['icerik'].tolist()\n",
    "summaries = df['ozet'].tolist()\n",
    "\n",
    "# Veriyi ilk olarak train ve test olarak ayırıyoruz\n",
    "train_articles, test_articles, train_summaries, test_summaries = train_test_split(\n",
    "    articles, summaries, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train setini bir daha ayırarak train ve validation setlerini oluşturuyoruz\n",
    "train_articles, val_articles, train_summaries, val_summaries = train_test_split(\n",
    "    train_articles, train_summaries, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train set size: {len(train_articles)}\")\n",
    "print(f\"Validation set size: {len(val_articles)}\")\n",
    "print(f\"Test set size: {len(test_articles)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T11:24:19.574127Z",
     "iopub.status.busy": "2024-12-11T11:24:19.573186Z",
     "iopub.status.idle": "2024-12-11T11:24:19.610785Z",
     "shell.execute_reply": "2024-12-11T11:24:19.609835Z",
     "shell.execute_reply.started": "2024-12-11T11:24:19.574081Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Her bir seti Hugging Face Dataset formatına dönüştürme\n",
    "train_data = {'article': train_articles, 'summary': train_summaries}\n",
    "val_data = {'article': val_articles, 'summary': val_summaries}\n",
    "test_data = {'article': test_articles, 'summary': test_summaries}\n",
    "\n",
    "train_dataset = Dataset.from_dict(train_data)\n",
    "val_dataset = Dataset.from_dict(val_data)\n",
    "test_dataset = Dataset.from_dict(test_data)\n",
    "\n",
    "# DatasetDict formatında birleştirme\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T11:24:21.981763Z",
     "iopub.status.busy": "2024-12-11T11:24:21.981381Z",
     "iopub.status.idle": "2024-12-11T11:24:37.360323Z",
     "shell.execute_reply": "2024-12-11T11:24:37.359069Z",
     "shell.execute_reply.started": "2024-12-11T11:24:21.981731Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b97cac8ab604714ae3ea42e09e4f76a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1545ca9a1e648f5a3582adf6e6a5e76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.44G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "163142a9873c40d19c6a193155f61236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/261 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea0078294e4d4268bdd975bbfb24cff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/531 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b92d43b7d05842d2b7d53a15ab02cb40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e16ddda72f5a4cef9d8547f08d7b2a66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/649 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load tokenizer and model\n",
    "model_name = 'facebook/mbart-large-50'\n",
    "model = MBartForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T11:24:40.007375Z",
     "iopub.status.busy": "2024-12-11T11:24:40.006984Z",
     "iopub.status.idle": "2024-12-11T11:24:40.012006Z",
     "shell.execute_reply": "2024-12-11T11:24:40.010957Z",
     "shell.execute_reply.started": "2024-12-11T11:24:40.007342Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T11:24:42.640934Z",
     "iopub.status.busy": "2024-12-11T11:24:42.640485Z",
     "iopub.status.idle": "2024-12-11T11:24:43.042911Z",
     "shell.execute_reply": "2024-12-11T11:24:43.041998Z",
     "shell.execute_reply.started": "2024-12-11T11:24:42.640903Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8af2e4d374646c9bbda66deb8337c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/172 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bacadde19be941d182f64a0175ce6739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e293226d06d14440a6a5604a0c4e312d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/48 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_data(examples):\n",
    "    inputs = [f\"Özetle: {article}\" for article in examples[\"article\"]]\n",
    "    targets = examples['summary']\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
    "    labels = tokenizer(targets, max_length=150, truncation=True, padding=\"max_length\")\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "    \n",
    "tokenized_dataset = dataset.map(preprocess_data, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELİ EĞİT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T11:24:46.013675Z",
     "iopub.status.busy": "2024-12-11T11:24:46.013311Z",
     "iopub.status.idle": "2024-12-11T11:24:52.080827Z",
     "shell.execute_reply": "2024-12-11T11:24:52.080041Z",
     "shell.execute_reply.started": "2024-12-11T11:24:46.013643Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./results',\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=100,\n",
    "    weight_decay=0.01,\n",
    "    predict_with_generate=True,\n",
    "    logging_dir='./logs',\n",
    "    report_to=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T11:24:54.682089Z",
     "iopub.status.busy": "2024-12-11T11:24:54.681418Z",
     "iopub.status.idle": "2024-12-11T12:27:01.138949Z",
     "shell.execute_reply": "2024-12-11T12:27:01.138222Z",
     "shell.execute_reply.started": "2024-12-11T11:24:54.682055Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4300' max='4300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4300/4300 1:02:03, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.868989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.147313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.191697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.035647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.039966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.090554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.106848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.191663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.176535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.254847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.265086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.167900</td>\n",
       "      <td>1.308662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.167900</td>\n",
       "      <td>1.316775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.167900</td>\n",
       "      <td>1.299034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.167900</td>\n",
       "      <td>1.309769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>1.167900</td>\n",
       "      <td>1.320334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.167900</td>\n",
       "      <td>1.329226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.167900</td>\n",
       "      <td>1.345253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.167900</td>\n",
       "      <td>1.352877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.167900</td>\n",
       "      <td>1.402560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.167900</td>\n",
       "      <td>1.387631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.167900</td>\n",
       "      <td>1.426048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.167900</td>\n",
       "      <td>1.419585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>1.420607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>1.412720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>1.423329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>1.425979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>1.441851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>1.425758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>1.447290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>1.436109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>1.425340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>1.469040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>1.445486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.470229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.431777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.423721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.438577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.418976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.441217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.454141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.481916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.471444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.450588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.471947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.481173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.499252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.499251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.491732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.496803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.510699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.511067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.497960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.506051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.502041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.499939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.495444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>1.506029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.504221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.502649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.504984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.510263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.511564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.519110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.516636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.523748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.514887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.529804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>1.526613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.541869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.543700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.540881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.542647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.549865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.542593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.543533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.543331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.536648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.542043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.547058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.549122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.551962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.558976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.555906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.556479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.556597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.552970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.552831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.555888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.558225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.558982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.543784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>1.545316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.545103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.546339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.547228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.548115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.548743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.548790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.548940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4300, training_loss=0.13793005899634472, metrics={'train_runtime': 3725.1399, 'train_samples_per_second': 4.617, 'train_steps_per_second': 1.154, 'total_flos': 1.86373160042496e+16, 'train_loss': 0.13793005899634472, 'epoch': 100.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Seq2SeqTrainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T12:36:11.055968Z",
     "iopub.status.busy": "2024-12-11T12:36:11.055191Z",
     "iopub.status.idle": "2024-12-11T12:36:16.777120Z",
     "shell.execute_reply": "2024-12-11T12:36:16.776179Z",
     "shell.execute_reply.started": "2024-12-11T12:36:11.055933Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 200, 'early_stopping': True, 'num_beams': 5}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning complete. Model and tokenizer saved.\n"
     ]
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"fine_tuned_mt5-base-200\")\n",
    "tokenizer.save_pretrained(\"fine_tuned_mt5-base-200\")\n",
    "\n",
    "print(\"Fine-tuning complete. Model and tokenizer saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T12:36:30.805157Z",
     "iopub.status.busy": "2024-12-11T12:36:30.804393Z",
     "iopub.status.idle": "2024-12-11T12:36:30.810249Z",
     "shell.execute_reply": "2024-12-11T12:36:30.809402Z",
     "shell.execute_reply.started": "2024-12-11T12:36:30.805123Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_summary(model, tokenizer, text, max_length=150, min_length=30):\n",
    "    \"\"\"Haber metni için özet oluşturma.\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    text = f'Özetle {text}'\n",
    "    input_ids = tokenizer.encode(text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "    summary_ids = model.generate(input_ids, max_length=max_length, min_length=min_length, num_beams=4, early_stopping=True)\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T12:36:33.171333Z",
     "iopub.status.busy": "2024-12-11T12:36:33.170507Z",
     "iopub.status.idle": "2024-12-11T12:36:33.180908Z",
     "shell.execute_reply": "2024-12-11T12:36:33.180111Z",
     "shell.execute_reply.started": "2024-12-11T12:36:33.171299Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ROUGE Hesaplama Fonksiyonu\n",
    "def evaluate_rouge(model, tokenizer):\n",
    "    print(\"Calculating ROUGE scores...\")\n",
    "    rouge_results = []\n",
    "\n",
    "    for article, reference_summary in zip(test_articles, test_summaries):\n",
    "        predicted_summary = generate_summary(model, tokenizer, article)\n",
    "        rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "        scores = rouge.score(predicted_summary, reference_summary)\n",
    "        rouge_results.append({\n",
    "            \"rouge1_f1\": scores['rouge1'].fmeasure,\n",
    "            \"rouge2_f1\": scores['rouge2'].fmeasure,\n",
    "            \"rougeL_f1\": scores['rougeL'].fmeasure\n",
    "        })\n",
    "\n",
    "    avg_rouge = {\n",
    "        key: sum(d[key] for d in rouge_results) / len(rouge_results)\n",
    "        for key in rouge_results[0]\n",
    "    }\n",
    "    print(f\"Average ROUGE Scores: {avg_rouge}\")\n",
    "\n",
    "# BLEU Hesaplama Fonksiyonu\n",
    "def evaluate_bleu(model, tokenizer):\n",
    "    print(\"Calculating BLEU scores...\")\n",
    "    bleu_results = []\n",
    "\n",
    "    for article, reference_summary in zip(test_articles, test_summaries):\n",
    "        predicted_summary = generate_summary(model, tokenizer, article)\n",
    "        bleu_score = sacrebleu.sentence_bleu(predicted_summary, [reference_summary]).score\n",
    "        bleu_results.append(bleu_score)\n",
    "\n",
    "    avg_bleu = sum(bleu_results) / len(bleu_results)\n",
    "    print(f\"Average BLEU Score: {avg_bleu:.4f}\")\n",
    "    # Corpus BLEU Hesaplama Fonksiyonu\n",
    "\n",
    "def evaluate_corpus_bleu(model, tokenizer):\n",
    "    print(\"Calculating Corpus BLEU score...\")\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    for article, reference_summary in zip(test_articles, test_summaries):\n",
    "        predicted_summary = generate_summary(model, tokenizer, article)\n",
    "        predictions.append(predicted_summary)\n",
    "        references.append([reference_summary])  # SacreBLEU çoklu referansı destekler, bu yüzden liste içinde olmalı\n",
    "\n",
    "    bleu_score = sacrebleu.corpus_bleu(predictions, references).score\n",
    "    print(f\"Corpus BLEU Score: {bleu_score:.4f}\")\n",
    "\n",
    "# BERTScore Hesaplama Fonksiyonu\n",
    "def evaluate_bertscore(model, tokenizer):\n",
    "    print(\"Calculating BERTScore...\")\n",
    "    bert_results = []\n",
    "\n",
    "    for article, reference_summary in zip(test_articles, test_summaries):\n",
    "        predicted_summary = generate_summary(model, tokenizer, article)\n",
    "        P, R, F1 = bert_score([predicted_summary], [reference_summary], lang=\"tr\")\n",
    "        bert_results.append(F1.mean().item())\n",
    "\n",
    "    avg_bert = sum(bert_results) / len(bert_results)\n",
    "    print(f\"Average BERTScore: {avg_bert:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T12:36:35.664437Z",
     "iopub.status.busy": "2024-12-11T12:36:35.663775Z",
     "iopub.status.idle": "2024-12-11T12:37:15.062708Z",
     "shell.execute_reply": "2024-12-11T12:37:15.061832Z",
     "shell.execute_reply.started": "2024-12-11T12:36:35.664406Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating ROUGE scores...\n",
      "Average ROUGE Scores: {'rouge1_f1': 0.45135512419103163, 'rouge2_f1': 0.25798465126317166, 'rougeL_f1': 0.33991424992644675}\n"
     ]
    }
   ],
   "source": [
    "evaluate_rouge(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T12:37:19.262513Z",
     "iopub.status.busy": "2024-12-11T12:37:19.261874Z",
     "iopub.status.idle": "2024-12-11T12:38:37.402910Z",
     "shell.execute_reply": "2024-12-11T12:38:37.402030Z",
     "shell.execute_reply.started": "2024-12-11T12:37:19.262478Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating BLEU scores...\n",
      "Average BLEU Score: 11.8276\n",
      "Calculating Corpus BLEU score...\n",
      "Corpus BLEU Score: 40.2802\n"
     ]
    }
   ],
   "source": [
    "evaluate_bleu(model, tokenizer)\n",
    "evaluate_corpus_bleu(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T12:38:53.139756Z",
     "iopub.status.busy": "2024-12-11T12:38:53.139408Z",
     "iopub.status.idle": "2024-12-11T12:39:51.680729Z",
     "shell.execute_reply": "2024-12-11T12:39:51.679879Z",
     "shell.execute_reply.started": "2024-12-11T12:38:53.139727Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating BERTScore...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9edc480f00f44550890d437a704decfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/60.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9566e5824c34077b67828b58e0e744e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec87eb70a6d243da8d25f6300cdfce9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/251k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e4e40afc9bb48648a2ccd07ebdd22bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/445M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BERTScore: 0.7089\n"
     ]
    }
   ],
   "source": [
    "evaluate_bertscore(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-11T12:40:15.579342Z",
     "iopub.status.busy": "2024-12-11T12:40:15.578976Z",
     "iopub.status.idle": "2024-12-11T12:40:16.478750Z",
     "shell.execute_reply": "2024-12-11T12:40:16.477858Z",
     "shell.execute_reply.started": "2024-12-11T12:40:15.579310Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------ Rastgele Seçilen Haber 41 ------\n",
      "--- Orijinal Metin ---\n",
      "VakıfBank, 2023 yıl sonu finansal sonuçlarını kamuoyu ile paylaştı. Bankanın 2023 yıl sonu finansal sonuçlarına ilişkin değerlendirmelerde bulunan VakıfBank Genel Müdürü Abdi Serdar Üstünsalih, “2023 yılı, özellikle ikinci yarısından itibaren, ülkemiz için pek çok olumlu gelişmenin yaşandığı, Türk bankacılık sektörünün her koşul ve şartta ne kadar dirençli olduğunu bir kez daha kanıtladığı ve ekonomi yönetimimizin izlediği makro ekonomik politikalarla yabancı yatırımcıların ülkemize ve Türk bankalarına yönelik pozitif algılarının giderek arttığı bir dönem oldu. Türkiye’nin aktiflerde en büyük iki bankasından birisi olarak gerek verimli bilanço yönetimimiz gerekse uluslararası piyasalardaki öncü rolümüzün de katkısıyla gerçekleştirdiğimiz işlemlerimizle ülkemiz ekonomisine kesintisiz desteğimizi sürdürdük” dedi. Ekonomik büyüme için ana kalemlerden olan ihracat ve yatırım odaklı projeleri desteklediklerini dile getiren Üstünsalih, sözlerine şu şekilde devam etti: “Ülkemiz istihdamına katkı sağlayan ticari ve KOBİ kredilerinde büyüme stratejimizle toplam ticari kredi portföy büyüklüğümüz 1,2 trilyon TL’yi, TL kredi portföyümüz ise ilk defa 1 trilyon TL seviyesini aştı. Bir yandan reel ekonomiye ve firmalarımıza finansal desteğimizi sürdürürken diğer taraftan ihtiyatlılık yaklaşımımız doğrultusunda her alanda kredi karşılıklarımızı artırdık. Böylece Bankamızın toplam karşılık oranı ilk defa yüzde 300 üzerinde seyrederek tarihinin en yüksek seviyesine ulaşmış oldu. Bu oran, Bankamızın olası risklere karşı ihtiyatlı ve sağlam duruşunun bir göstergesidir. Önümüzdeki dönemde de seçici kredi politikamız doğrultusunda, reel ekonomiye ihtiyaç duyduğu finansal desteği sağlamaya devam edeceğiz” ifadelerini kullandı. Bankanın ana fonlama kalemi olan mevduatlar tarafındaki performansına da değinen Üstünsalih, “Tabana yaygın mevduat yapısı ve müşteri portföyü stratejimiz doğrultusunda tüm müşterilerimizin ihtiyaçlarına yönelik özel ürünler geliştirmeye ve yenilikçi çözümler sunmaya devam ediyoruz. Toplam mevduatlarımız yıllık bazda yüzde 74 artışla 2 trilyon TL’ye yaklaştı. Böylece bu alandaki pazar payımız bir önceki yıl yüzde 12,7 olan seviyesinden yüzde 13,2’ye yükseldi. TL vadeli mevduatlar ise ilk defa 1 trilyon seviyesini aştı. Bir yandan müşterilerimizin tasarruflarını doğru bir şekilde değerlendirirken, diğer yandan tüm finansal ihtiyaçlarına kusursuz bir şekilde karşılık vererek bütün bankacılık işlemlerini gerçekleştirdikleri ana bankaları olmak için çalışmalarımıza hızla devam ediyoruz” dedi. Üstünsalih, ‘’2023 yılında yurtdışı fonlama tarafında gerçekleştirdiğimiz 2 milyar dolar büyüklüğündeki DPR seküritizasyon işlemi ile Türk bankaları arasında tek seferde gerçekleştirilen en büyük tutarlı DPR seküritizasyon işlemine de imzamızı attık. Ardından 750 milyon dolarlık sürdürülebilir Eurobond işlemi, sendikasyon kredileri, teminatlı fonlama işlemleri ve çok uluslu finansal kuruluşlar ile gerçekleştirilen işlemler ile uluslararası piyasalardaki en aktif Türk bankası olmayı sürdürdük” dedi. Yurtdışından gerçekleştirilen fonlamaların Türkiye ve bankacılık sektörü için önemine vurgu yaparak Üstünsalih, sözlerini şu şekilde tamamladı: “Yıl boyunca yurtdışından sağladığımız taze kaynak tutarı 6,3 milyar dolar olurken, uluslararası piyasalardan temin ettiğimiz yabancı kaynak toplamı ise 14 milyar dolar oldu. Türkiye ve Türk bankalarına yönelik iyileşen yabancı yatırımcı algısının yansıra yılın ikinci yarısında ülkemize yönelik derecelendirme kuruluşlarından gelecek olası bir not artışının kaçınılmaz olduğunu düşünüyorum. Şüphesiz 2024 yılı ülkemiz ve bankamız açısından oldukça verimli bir yıl olacaktır.”\n",
      "--- Modelin Oluşturduğu Özet ---\n",
      "VakıfBank, 2023 yılının ilk yarısında 1,2 trilyon TL kredi portföy elde etti ve ticari kredilerde büyüme stratejisi doğrultusunda kredi karşılıklarını artırdı. Kredi portföy büyüklüğü 1,2 trilyon TL'ye ulaşırken, aktiflerde en büyük iki bankadan biri oldu.\n",
      "--- Gerçek Özet ---\n",
      "VakıfBank, 2023 yılında aktif büyüklüğünü yüzde 66 artırarak 2,8 trilyon TL'ye ulaştırdı. Bankanın nakdi kredileri yüzde 61 artışla 1,5 trilyon TL'yi bulurken, ekonomiye sağladığı finansman desteği ise 1,9 trilyon TL’yi aştı. Banka, seçici kredi politikası ile reel ekonomiye desteğini sürdürüyor ve yurtdışı fonlamalar yoluyla 6,3 milyar dolar taze kaynak sağladı.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "# Rastgele bir örnek seçme\n",
    "random_index = random.randint(0, len(test_articles) - 1)\n",
    "article = test_articles[random_index]\n",
    "reference_summary = test_summaries[random_index]\n",
    "predicted_summary = generate_summary(model, tokenizer, article)\n",
    "\n",
    "# Seçilen rastgele örneği yazdırma\n",
    "print(f\"\\n------ Rastgele Seçilen Haber {random_index + 1} ------\")\n",
    "print(f\"--- Orijinal Metin ---\\n{article}\")\n",
    "print(f\"--- Modelin Oluşturduğu Özet ---\\n{predicted_summary}\")\n",
    "print(f\"--- Gerçek Özet ---\\n{reference_summary}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5947269,
     "sourceId": 9720602,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6205643,
     "sourceId": 10068647,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
