{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-10T20:15:01.672480Z",
     "iopub.status.busy": "2024-12-10T20:15:01.672144Z",
     "iopub.status.idle": "2024-12-10T20:15:13.540722Z",
     "shell.execute_reply": "2024-12-10T20:15:13.539782Z",
     "shell.execute_reply.started": "2024-12-10T20:15:01.672446Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.1.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\n",
      "Collecting rouge-score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting bert-score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting sacrebleu\n",
      "  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge-score) (3.2.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from bert-score) (3.7.5)\n",
      "Collecting portalocker (from sacrebleu)\n",
      "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /opt/conda/lib/python3.10/site-packages (from sacrebleu) (5.3.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (1.4.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->bert-score) (10.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
      "Building wheels for collected packages: rouge-score\n",
      "  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=421a97245eba24485d3b34f941ca3b56e17ad99bcad86bae1fcb4e205938776b\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge-score\n",
      "Installing collected packages: portalocker, sacrebleu, rouge-score, bert-score\n",
      "Successfully installed bert-score-0.3.13 portalocker-3.0.0 rouge-score-0.1.2 sacrebleu-2.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas torch transformers datasets scikit-learn rouge-score bert-score sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T20:15:18.951263Z",
     "iopub.status.busy": "2024-12-10T20:15:18.950488Z",
     "iopub.status.idle": "2024-12-10T20:15:38.428609Z",
     "shell.execute_reply": "2024-12-10T20:15:38.427890Z",
     "shell.execute_reply.started": "2024-12-10T20:15:18.951226Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import MT5Tokenizer, MT5ForConditionalGeneration, Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n",
    "from datasets import Dataset, DatasetDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score as bert_score\n",
    "import sacrebleu\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T20:15:40.317029Z",
     "iopub.status.busy": "2024-12-10T20:15:40.316343Z",
     "iopub.status.idle": "2024-12-10T20:15:40.365607Z",
     "shell.execute_reply": "2024-12-10T20:15:40.364707Z",
     "shell.execute_reply.started": "2024-12-10T20:15:40.316992Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 172\n",
      "Validation set size: 20\n",
      "Test set size: 48\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "input_path = '/kaggle/input/eco-news-me/haberler.csv'\n",
    "if not os.path.exists(input_path):\n",
    "    raise FileNotFoundError(f\"File not found: {input_path}\")\n",
    "\n",
    "# Read CSV file\n",
    "df = pd.read_csv(input_path)\n",
    "\n",
    "# Drop rows with NaN values in 'icerik' or 'ozet' columns\n",
    "df = df.dropna(subset=['icerik', 'ozet'])\n",
    "\n",
    "# Separate articles and summaries\n",
    "articles = df['icerik'].tolist()\n",
    "summaries = df['ozet'].tolist()\n",
    "\n",
    "# Veriyi ilk olarak train ve test olarak ayırıyoruz\n",
    "train_articles, test_articles, train_summaries, test_summaries = train_test_split(\n",
    "    articles, summaries, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train setini bir daha ayırarak train ve validation setlerini oluşturuyoruz\n",
    "train_articles, val_articles, train_summaries, val_summaries = train_test_split(\n",
    "    train_articles, train_summaries, test_size=0.1, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train set size: {len(train_articles)}\")\n",
    "print(f\"Validation set size: {len(val_articles)}\")\n",
    "print(f\"Test set size: {len(test_articles)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T20:15:49.182996Z",
     "iopub.status.busy": "2024-12-10T20:15:49.182637Z",
     "iopub.status.idle": "2024-12-10T20:15:49.222188Z",
     "shell.execute_reply": "2024-12-10T20:15:49.221480Z",
     "shell.execute_reply.started": "2024-12-10T20:15:49.182963Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Her bir seti Hugging Face Dataset formatına dönüştürme\n",
    "train_data = {'article': train_articles, 'summary': train_summaries}\n",
    "val_data = {'article': val_articles, 'summary': val_summaries}\n",
    "test_data = {'article': test_articles, 'summary': test_summaries}\n",
    "\n",
    "train_dataset = Dataset.from_dict(train_data)\n",
    "val_dataset = Dataset.from_dict(val_data)\n",
    "test_dataset = Dataset.from_dict(test_data)\n",
    "\n",
    "# DatasetDict formatında birleştirme\n",
    "dataset = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': val_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T20:15:51.589694Z",
     "iopub.status.busy": "2024-12-10T20:15:51.589383Z",
     "iopub.status.idle": "2024-12-10T20:16:06.597626Z",
     "shell.execute_reply": "2024-12-10T20:16:06.596763Z",
     "shell.execute_reply.started": "2024-12-10T20:15:51.589668Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8114903873214231ab1ab342cf332933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/376 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b4edc719f8f4a5da7fccc797c8e94e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/4.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd387d829633458f8f1f23ed09f36a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "355a677c8f7040da886c83473c86b234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/702 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f246ab5926462e8ee3267a221d54e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.33G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be9fe3456f847c6854720471782f482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load tokenizer and model\n",
    "model_name = 'google/mt5-base'\n",
    "tokenizer = MT5Tokenizer.from_pretrained(model_name)\n",
    "model = MT5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T20:16:13.926452Z",
     "iopub.status.busy": "2024-12-10T20:16:13.926132Z",
     "iopub.status.idle": "2024-12-10T20:16:13.932004Z",
     "shell.execute_reply": "2024-12-10T20:16:13.930656Z",
     "shell.execute_reply.started": "2024-12-10T20:16:13.926424Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T20:16:15.986749Z",
     "iopub.status.busy": "2024-12-10T20:16:15.986402Z",
     "iopub.status.idle": "2024-12-10T20:16:22.960478Z",
     "shell.execute_reply": "2024-12-10T20:16:22.959458Z",
     "shell.execute_reply.started": "2024-12-10T20:16:15.986717Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91d5b91a800e41b891a099241139b583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/172 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d1ecd62d8bb402fbe40cb0fdb50b85a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a08ad8e6b4224744b0db6a3c3d8d4715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/48 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_data(examples):\n",
    "    inputs = [f\"Özetle: {article}\" for article in examples[\"article\"]]\n",
    "    targets = examples['summary']\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n",
    "    labels = tokenizer(targets, max_length=150, truncation=True, padding=\"max_length\")\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "    \n",
    "tokenized_dataset = dataset.map(preprocess_data, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T20:16:36.372081Z",
     "iopub.status.busy": "2024-12-10T20:16:36.371046Z",
     "iopub.status.idle": "2024-12-10T20:16:36.543759Z",
     "shell.execute_reply": "2024-12-10T20:16:36.542830Z",
     "shell.execute_reply.started": "2024-12-10T20:16:36.372019Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir='./results',\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=100,\n",
    "    weight_decay=0.01,\n",
    "    predict_with_generate=True,\n",
    "    logging_dir='./logs',\n",
    "    report_to=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T20:16:38.930416Z",
     "iopub.status.busy": "2024-12-10T20:16:38.929641Z",
     "iopub.status.idle": "2024-12-10T21:00:49.423298Z",
     "shell.execute_reply": "2024-12-10T21:00:49.422510Z",
     "shell.execute_reply.started": "2024-12-10T20:16:38.930383Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4300' max='4300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4300/4300 44:07, Epoch 100/100]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>24.690994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>22.679195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>21.919796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>20.570074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>19.160763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>17.576656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>16.479252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>15.500549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>13.231809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>12.556984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>11.236995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>20.899700</td>\n",
       "      <td>10.027975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>20.899700</td>\n",
       "      <td>8.822993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>20.899700</td>\n",
       "      <td>8.230218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>20.899700</td>\n",
       "      <td>7.333681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>20.899700</td>\n",
       "      <td>6.537413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>20.899700</td>\n",
       "      <td>6.723670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>20.899700</td>\n",
       "      <td>6.020039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>20.899700</td>\n",
       "      <td>5.542735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>20.899700</td>\n",
       "      <td>5.342281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>20.899700</td>\n",
       "      <td>5.104232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>20.899700</td>\n",
       "      <td>4.861568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>20.899700</td>\n",
       "      <td>4.612695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>8.154800</td>\n",
       "      <td>4.491952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>8.154800</td>\n",
       "      <td>4.392161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>8.154800</td>\n",
       "      <td>4.301023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>8.154800</td>\n",
       "      <td>4.248393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>8.154800</td>\n",
       "      <td>4.241828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>8.154800</td>\n",
       "      <td>4.274904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>8.154800</td>\n",
       "      <td>4.185006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>8.154800</td>\n",
       "      <td>4.213326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>8.154800</td>\n",
       "      <td>4.059840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>8.154800</td>\n",
       "      <td>4.034374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>8.154800</td>\n",
       "      <td>3.964457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>4.518600</td>\n",
       "      <td>4.685035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>4.518600</td>\n",
       "      <td>3.763726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>4.518600</td>\n",
       "      <td>6.119496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>4.518600</td>\n",
       "      <td>5.356630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>4.518600</td>\n",
       "      <td>6.289094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>4.518600</td>\n",
       "      <td>4.836056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>4.518600</td>\n",
       "      <td>1.444773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>4.518600</td>\n",
       "      <td>1.846932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>4.518600</td>\n",
       "      <td>1.365278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>4.518600</td>\n",
       "      <td>1.339815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>4.518600</td>\n",
       "      <td>1.291049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>4.518600</td>\n",
       "      <td>1.204042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>2.670700</td>\n",
       "      <td>1.149881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>2.670700</td>\n",
       "      <td>1.149875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>2.670700</td>\n",
       "      <td>1.138199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.670700</td>\n",
       "      <td>1.138570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>2.670700</td>\n",
       "      <td>1.136669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>2.670700</td>\n",
       "      <td>1.125276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>2.670700</td>\n",
       "      <td>1.123536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>2.670700</td>\n",
       "      <td>1.114755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>2.670700</td>\n",
       "      <td>1.124854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>2.670700</td>\n",
       "      <td>1.119799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>2.670700</td>\n",
       "      <td>1.105725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>2.670700</td>\n",
       "      <td>1.098471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.652700</td>\n",
       "      <td>1.101897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.652700</td>\n",
       "      <td>1.101306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>1.652700</td>\n",
       "      <td>1.090674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>1.652700</td>\n",
       "      <td>1.084840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>1.652700</td>\n",
       "      <td>1.084842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>1.652700</td>\n",
       "      <td>1.077399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>1.652700</td>\n",
       "      <td>1.070726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>1.652700</td>\n",
       "      <td>1.072906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>1.652700</td>\n",
       "      <td>1.067621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>1.652700</td>\n",
       "      <td>1.069214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>1.652700</td>\n",
       "      <td>1.067707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.237300</td>\n",
       "      <td>1.063979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>1.237300</td>\n",
       "      <td>1.064133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>1.237300</td>\n",
       "      <td>1.062484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>1.237300</td>\n",
       "      <td>1.059802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>1.237300</td>\n",
       "      <td>1.060272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>1.237300</td>\n",
       "      <td>1.059590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>1.237300</td>\n",
       "      <td>1.059783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>1.237300</td>\n",
       "      <td>1.061044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>1.237300</td>\n",
       "      <td>1.059021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>1.237300</td>\n",
       "      <td>1.058448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.237300</td>\n",
       "      <td>1.057356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>1.237300</td>\n",
       "      <td>1.057638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>1.132700</td>\n",
       "      <td>1.056739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>1.132700</td>\n",
       "      <td>1.055958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>1.132700</td>\n",
       "      <td>1.054782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>1.132700</td>\n",
       "      <td>1.052793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>1.132700</td>\n",
       "      <td>1.052394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>1.132700</td>\n",
       "      <td>1.051857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>1.132700</td>\n",
       "      <td>1.049990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>1.132700</td>\n",
       "      <td>1.049353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.132700</td>\n",
       "      <td>1.049188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>1.132700</td>\n",
       "      <td>1.049295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>1.132700</td>\n",
       "      <td>1.048262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>1.132700</td>\n",
       "      <td>1.048749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>1.075700</td>\n",
       "      <td>1.048510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>1.075700</td>\n",
       "      <td>1.048611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>1.075700</td>\n",
       "      <td>1.048304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>1.075700</td>\n",
       "      <td>1.048012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>1.075700</td>\n",
       "      <td>1.048233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>1.075700</td>\n",
       "      <td>1.048311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.075700</td>\n",
       "      <td>1.048249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4300, training_loss=4.880793613167696, metrics={'train_runtime': 2649.259, 'train_samples_per_second': 6.492, 'train_steps_per_second': 1.623, 'total_flos': 2.06235934654464e+16, 'train_loss': 4.880793613167696, 'epoch': 100.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Seq2SeqTrainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T21:01:39.250246Z",
     "iopub.status.busy": "2024-12-10T21:01:39.249464Z",
     "iopub.status.idle": "2024-12-10T21:01:44.823231Z",
     "shell.execute_reply": "2024-12-10T21:01:44.822381Z",
     "shell.execute_reply.started": "2024-12-10T21:01:39.250214Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning complete. Model and tokenizer saved.\n"
     ]
    }
   ],
   "source": [
    "# Save the fine-tuned model\n",
    "model.save_pretrained(\"fine_tuned_mt5-base-200\")\n",
    "tokenizer.save_pretrained(\"fine_tuned_mt5-base-200\")\n",
    "\n",
    "print(\"Fine-tuning complete. Model and tokenizer saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T21:01:49.696073Z",
     "iopub.status.busy": "2024-12-10T21:01:49.695261Z",
     "iopub.status.idle": "2024-12-10T21:01:49.701266Z",
     "shell.execute_reply": "2024-12-10T21:01:49.700293Z",
     "shell.execute_reply.started": "2024-12-10T21:01:49.696039Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_summary(model, tokenizer, text, max_length=150, min_length=30):\n",
    "    \"\"\"Haber metni için özet oluşturma.\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    text = f'Özetle {text}'\n",
    "    input_ids = tokenizer.encode(text, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "    summary_ids = model.generate(input_ids, max_length=max_length, min_length=min_length, num_beams=4, early_stopping=True)\n",
    "    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T21:01:55.526065Z",
     "iopub.status.busy": "2024-12-10T21:01:55.525349Z",
     "iopub.status.idle": "2024-12-10T21:01:55.535818Z",
     "shell.execute_reply": "2024-12-10T21:01:55.534849Z",
     "shell.execute_reply.started": "2024-12-10T21:01:55.526031Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ROUGE Hesaplama Fonksiyonu\n",
    "def evaluate_rouge(model, tokenizer):\n",
    "    print(\"Calculating ROUGE scores...\")\n",
    "    rouge_results = []\n",
    "\n",
    "    for article, reference_summary in zip(test_articles, test_summaries):\n",
    "        predicted_summary = generate_summary(model, tokenizer, article)\n",
    "        rouge = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "        scores = rouge.score(predicted_summary, reference_summary)\n",
    "        rouge_results.append({\n",
    "            \"rouge1_f1\": scores['rouge1'].fmeasure,\n",
    "            \"rouge2_f1\": scores['rouge2'].fmeasure,\n",
    "            \"rougeL_f1\": scores['rougeL'].fmeasure\n",
    "        })\n",
    "\n",
    "    avg_rouge = {\n",
    "        key: sum(d[key] for d in rouge_results) / len(rouge_results)\n",
    "        for key in rouge_results[0]\n",
    "    }\n",
    "    print(f\"Average ROUGE Scores: {avg_rouge}\")\n",
    "\n",
    "# BLEU Hesaplama Fonksiyonu\n",
    "def evaluate_bleu(model, tokenizer):\n",
    "    print(\"Calculating BLEU scores...\")\n",
    "    bleu_results = []\n",
    "\n",
    "    for article, reference_summary in zip(test_articles, test_summaries):\n",
    "        predicted_summary = generate_summary(model, tokenizer, article)\n",
    "        bleu_score = sacrebleu.sentence_bleu(predicted_summary, [reference_summary]).score\n",
    "        bleu_results.append(bleu_score)\n",
    "\n",
    "    avg_bleu = sum(bleu_results) / len(bleu_results)\n",
    "    print(f\"Average BLEU Score: {avg_bleu:.4f}\")\n",
    "    # Corpus BLEU Hesaplama Fonksiyonu\n",
    "\n",
    "def evaluate_corpus_bleu(model, tokenizer):\n",
    "    print(\"Calculating Corpus BLEU score...\")\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    for article, reference_summary in zip(test_articles, test_summaries):\n",
    "        predicted_summary = generate_summary(model, tokenizer, article)\n",
    "        predictions.append(predicted_summary)\n",
    "        references.append([reference_summary])  # SacreBLEU çoklu referansı destekler, bu yüzden liste içinde olmalı\n",
    "\n",
    "    bleu_score = sacrebleu.corpus_bleu(predictions, references).score\n",
    "    print(f\"Corpus BLEU Score: {bleu_score:.4f}\")\n",
    "\n",
    "# BERTScore Hesaplama Fonksiyonu\n",
    "def evaluate_bertscore(model, tokenizer):\n",
    "    print(\"Calculating BERTScore...\")\n",
    "    bert_results = []\n",
    "\n",
    "    for article, reference_summary in zip(test_articles, test_summaries):\n",
    "        predicted_summary = generate_summary(model, tokenizer, article)\n",
    "        P, R, F1 = bert_score([predicted_summary], [reference_summary], lang=\"tr\")\n",
    "        bert_results.append(F1.mean().item())\n",
    "\n",
    "    avg_bert = sum(bert_results) / len(bert_results)\n",
    "    print(f\"Average BERTScore: {avg_bert:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-10T21:01:58.755745Z",
     "iopub.status.busy": "2024-12-10T21:01:58.755402Z",
     "iopub.status.idle": "2024-12-10T21:02:47.041072Z",
     "shell.execute_reply": "2024-12-10T21:02:47.040254Z",
     "shell.execute_reply.started": "2024-12-10T21:01:58.755715Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating ROUGE scores...\n",
      "Average ROUGE Scores: {'rouge1_f1': 0.3406938527776023, 'rouge2_f1': 0.1949513038906194, 'rougeL_f1': 0.27352491940321133}\n"
     ]
    }
   ],
   "source": [
    "evaluate_rouge(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "evaluate_bleu(model, tokenizer)\n",
    "evaluate_corpus_bleu(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "evaluate_bertscore(model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "# Rastgele bir örnek seçme\n",
    "random_index = random.randint(0, len(test_articles) - 1)\n",
    "article = test_articles[random_index]\n",
    "reference_summary = test_summaries[random_index]\n",
    "predicted_summary = generate_summary(model, tokenizer, article)\n",
    "\n",
    "# Seçilen rastgele örneği yazdırma\n",
    "print(f\"\\n------ Rastgele Seçilen Haber {random_index + 1} ------\")\n",
    "print(f\"--- Orijinal Metin ---\\n{article}\")\n",
    "print(f\"--- Modelin Oluşturduğu Özet ---\\n{predicted_summary}\")\n",
    "print(f\"--- Gerçek Özet ---\\n{reference_summary}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5947269,
     "sourceId": 9720602,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6205643,
     "sourceId": 10068647,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
